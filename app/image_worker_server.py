from __future__ import annotations

# asyncio removed - using sync notifications now
import io
import os
import tempfile
import time
import threading
from pathlib import Path
from typing import Any, Dict

from aiogram.types import InlineKeyboardMarkup
from loguru import logger
from rq import get_current_job
from PIL import Image

# JobTimeoutException –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ RQ 1.15.1, —Å–æ–∑–¥–∞–µ–º —Å–≤–æ–π –∫–ª–∞—Å—Å
class JobTimeoutException(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–∞–π–º–∞—É—Ç–æ–≤ –∑–∞–¥–∞—á RQ"""
    pass

from app.core.config import settings
from app.core.queues import get_job
import httpx

from app.providers.fal import (
    check_image_status,
    resolve_image_asset,
    run_smart_merge,
    submit_face_swap,
    submit_image,
    submit_image_edit,
    submit_image_upscale,
)

try:
    from app.providers.wavespeed.client import wavespeed_face_swap, wavespeed_text_to_image
    WAVESPEED_AVAILABLE = True
except ImportError:
    WAVESPEED_AVAILABLE = False
from app.providers.fal.client import download_file, run_model
from app.providers.fal.models_map import model_requires_mask
from app.providers.fal.images import _extract_image_url, ImageAsset
from app.providers.fal import images as fal_images
from app.utils.translation import translate_to_english
# Format conversion is not used - models receive aspect_ratio and return images with correct aspect ratio

# Import models and initialize database to ensure tables exist
from app.db import models  # noqa: F401
from app.db.base import init_db

# Initialize database on module import
try:
    init_db()
    logger.debug("Database initialized in image_worker")
except Exception as e:
    logger.warning("Failed to initialize database in image_worker: {}", e)

UPSCALE_MAX_EDGE = 4096
UPSCALE_INPUT_MAX_EDGE = 4096

SMART_MERGE_DEFAULT_MODEL = "fal-ai/nano-banana/edit"
SMART_MERGE_DEFAULT_SIZE = "1024x1024"
SMART_MERGE_DEFAULT_ASPECT_RATIO = "1:1"
RETOUCHER_SUBMIT_MAX_ATTEMPTS = 3
RETOUCHER_SUBMIT_BACKOFF = 2.0
RETOUCHER_POLL_MAX_ATTEMPTS = 240
# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ base64 –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º (10 –ú–ë –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–∞, base64 —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –Ω–∞ ~33%)
RETOUCHER_MAX_FILE_BYTES = 10 * 1024 * 1024  # 10 –ú–ë
RETOUCHER_MODELS = {
    "soft": settings.fal_retoucher_model,
    "enhance": "fal-ai/nano-banana/edit",  # Nano Banana Edit –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ—Ç—É—à–∏ –±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
}

FACE_SWAP_DEFAULT_MODEL = settings.fal_face_swap_model
FACE_SWAP_MAX_ATTEMPTS = 3
FACE_SWAP_RETRY_BASE_DELAY = 2.0

UPSCALE_MAX_ATTEMPTS = 3
UPSCALE_RETRY_BASE_DELAY = 2.0
UPSCALE_POLL_MAX_ATTEMPTS = 36  # 3 minutes max (36 * 5 seconds) - matches RQ job timeout

# Retry –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–æ–∫
from functools import wraps
from typing import Callable, TypeVar

T = TypeVar('T')

def retry_on_network_error(
    max_attempts: int = 3,
    base_delay: float = 2.0,
    retryable_status_codes: tuple[int, ...] = (500, 502, 503, 504, 429),
) -> Callable[[Callable[..., T]], Callable[..., T]]:
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–∞ –æ–ø–µ—Ä–∞—Ü–∏–π –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö.
    
    Args:
        max_attempts: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        base_delay: –ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)
        retryable_status_codes: HTTP —Å—Ç–∞—Ç—É—Å –∫–æ–¥—ã, –ø—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö —Å—Ç–æ–∏—Ç –ø–æ–≤—Ç–æ—Ä—è—Ç—å –∑–∞–ø—Ä–æ—Å
    """
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        def wrapper(*args, **kwargs) -> T:
            last_error: Exception | None = None
            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except httpx.RequestError as e:
                    # –°–µ—Ç–µ–≤—ã–µ –æ—à–∏–±–∫–∏ (—Ç–∞–π–º–∞—É—Ç—ã, —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ —Ç.–¥.)
                    last_error = e
                    if attempt < max_attempts:
                        delay = base_delay * attempt
                        logger.warning(
                            "{} attempt {}/{} failed with network error: {}. Retrying in {:.1f}s",
                            func.__name__,
                            attempt,
                            max_attempts,
                            str(e)[:100],
                            delay,
                        )
                        time.sleep(delay)
                    else:
                        logger.error(
                            "{} failed after {} attempts with network error: {}",
                            func.__name__,
                            max_attempts,
                            str(e)[:200],
                        )
                        raise
                except httpx.HTTPStatusError as e:
                    # HTTP –æ—à–∏–±–∫–∏
                    status_code = e.response.status_code if hasattr(e, 'response') else 0
                    if status_code in retryable_status_codes and attempt < max_attempts:
                        delay = base_delay * attempt
                        logger.warning(
                            "{} attempt {}/{} failed with HTTP {}: {}. Retrying in {:.1f}s",
                            func.__name__,
                            attempt,
                            max_attempts,
                            status_code,
                            str(e)[:100],
                            delay,
                        )
                        time.sleep(delay)
                        last_error = e
                        continue
                    else:
                        # –ù–µ–ø–æ–≤—Ç–æ—Ä—è–µ–º—ã–µ –æ—à–∏–±–∫–∏ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                        logger.error(
                            "{} failed with HTTP {}: {}",
                            func.__name__,
                            status_code,
                            str(e)[:200],
                        )
                        raise
                except Exception as e:  # noqa: BLE001
                    # –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ - –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º
                    logger.error(
                        "{} failed with unexpected error: {}",
                        func.__name__,
                        str(e)[:200],
                    )
                    raise
            # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞, –∑–Ω–∞—á–∏—Ç –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
            if last_error:
                raise last_error
            raise RuntimeError(f"{func.__name__} failed after {max_attempts} attempts")
        return wrapper
    return decorator


# –û–±–µ—Ä—Ç–∫–∏ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–µ—Ç–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º retry
@retry_on_network_error(max_attempts=3, base_delay=2.0)
def _download_file_with_retry(url: str, path: str) -> None:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è download_file —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º retry –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö."""
    download_file(url, path)


@retry_on_network_error(max_attempts=3, base_delay=2.0)
def _resolve_image_asset_with_retry(result_url: str):
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è resolve_image_asset —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º retry –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö."""
    from app.providers.fal.images import resolve_result_asset as resolve_image_asset
    return resolve_image_asset(result_url)


def _extract_notify_options(options: Dict[str, Any]) -> dict[str, Any]:
    return {
        "chat_id": options.pop("notify_chat_id", None),
        "linked_chat_id": options.pop("notify_linked_chat_id", None),
        "message_thread_id": options.pop("notify_message_thread_id", None),
        "reply_to_message_id": options.pop("notify_reply_to_message_id", None),
        "prompt": options.pop("notify_prompt", None),
    }


def _check_job_timeout(job_id: str, notify_options: dict[str, Any] | None = None) -> None:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏ —Ç–∞–π–º–∞—É—Ç –∑–∞–¥–∞—á–∏.
    –ï—Å–ª–∏ —Ç–∞–π–º–∞—É—Ç –ø—Ä–µ–≤—ã—à–µ–Ω, –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ.
    """
    job = get_current_job()
    if not job:
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏—Å—Ç–µ–∫ –ª–∏ —Ç–∞–π–º–∞—É—Ç –∑–∞–¥–∞—á–∏
    try:
        # RQ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç JobTimeoutException –ø—Ä–∏ —Ç–∞–π–º–∞—É—Ç–µ
        # –ù–æ –º—ã –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        if hasattr(job, 'timeout') and job.timeout:
            # –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
            # (RQ —Å–∞–º –ø—Ä–µ—Ä–≤–µ—Ç –∑–∞–¥–∞—á—É –ø–æ —Ç–∞–π–º–∞—É—Ç—É)
            pass
    except JobTimeoutException:
        error_msg = "‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∏—Å—Ç–µ–∫–ª–æ (4 –º–∏–Ω—É—Ç—ã). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
        logger.error("Job {} timed out", job_id)
        if notify_options and notify_options.get("chat_id"):
            _send_failure_notification_sync(notify_options, job_id, error_msg)
        raise


def _handle_job_timeout(job_id: str, notify_options: dict[str, Any] | None, operation_type: str = "–∑–∞–¥–∞—á–∞") -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–∞–π–º–∞—É—Ç –∑–∞–¥–∞—á–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
    """
    error_msg = f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è {operation_type} –∏—Å—Ç–µ–∫–ª–æ (4 –º–∏–Ω—É—Ç—ã). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ —É–ø—Ä–æ—Å—Ç–∏—Ç–µ –∑–∞–ø—Ä–æ—Å."
    logger.error("Job {} timed out for operation: {}", job_id, operation_type)
    if notify_options and notify_options.get("chat_id"):
        try:
            _send_failure_notification_sync(notify_options, job_id, error_msg)
        except Exception as notify_exc:
            logger.error("Failed to send timeout notification for job {}: {}", job_id, notify_exc)


def _persist_asset(asset, output_path: str, skip_download: bool = False) -> Path | None:
    path = Path(output_path)
    path.parent.mkdir(parents=True, exist_ok=True)
    if asset.content is not None:
        logger.info("_persist_asset: writing {} bytes (synchronous) to {}", len(asset.content), path)
        path.write_bytes(asset.content)
        logger.info("_persist_asset: successfully saved {} bytes to {}", path.stat().st_size, path)
        return path
    if asset.url and not skip_download:
        try:
            logger.info("üì• SYNC DOWNLOAD START: {} -> {}", asset.url[:80], path)
            _download_file_with_retry(asset.url, path.as_posix())
            if path.exists():
                file_size = path.stat().st_size
                logger.info("‚úÖ SYNC DOWNLOAD COMPLETE: {} bytes ({:.2f} KB) saved to {}", 
                           file_size, file_size / 1024, path)
                return path
            else:
                logger.warning("_persist_asset: download completed but file does not exist: {}", path)
        except Exception as exc:  # noqa: BLE001
            logger.warning("Failed to persist remote asset {}: {}", asset.url, exc, exc_info=True)
    elif asset.url and skip_download:
        logger.info("_persist_asset: skipping download (skip_download=True), will use URL directly")
    return None


def _schedule_result_download(job_id: str, url: str, target_path: Path) -> None:
    def _worker() -> None:
        try:
            logger.info("üîÑ ASYNC DOWNLOAD START for job {}: {} -> {}", 
                       job_id, url[:80], target_path)
            # Determine file extension from URL or use target_path extension
            # Check URL for common image extensions
            url_lower = url.lower()
            if url_lower.endswith(".webp"):
                download_path = target_path.with_suffix(".webp")
            elif url_lower.endswith(".png"):
                download_path = target_path.with_suffix(".png")
            elif url_lower.endswith(".jpg") or url_lower.endswith(".jpeg"):
                download_path = target_path.with_suffix(".jpg")
            else:
                # Use target_path extension if URL doesn't have one
                download_path = target_path
            
            _download_file_with_retry(url, download_path.as_posix())

            if download_path.exists():
                file_size = download_path.stat().st_size
                logger.info("‚úÖ ASYNC DOWNLOAD COMPLETE for job {}: {} bytes ({:.2f} KB) saved to {}", 
                           job_id, file_size, file_size / 1024, download_path)

                # Convert webp to PNG if needed (for upscale operations)
                final_path = download_path
                if download_path.suffix.lower() == ".webp":
                    try:
                        png_path = target_path.with_suffix(".png")
                        logger.info("üîÑ Converting webp to PNG: {} -> {}", download_path, png_path)
                        
                        # Check if webp file exists
                        if not download_path.exists():
                            logger.error("‚ö†Ô∏è Webp file does not exist: {}", download_path)
                        else:
                            logger.info("üìÇ Opening webp file: {} (size: {} bytes)", download_path, download_path.stat().st_size)
                            
                            with Image.open(download_path) as img:
                                logger.info("üñºÔ∏è Image opened: mode={}, size={}", img.mode, img.size)
                                
                                # Convert RGBA to RGB if needed (remove alpha channel for better compatibility)
                                if img.mode in ("RGBA", "LA", "P"):
                                    logger.info("üîÑ Converting {} mode to RGB", img.mode)
                                    # Create white background
                                    rgb_img = Image.new("RGB", img.size, (255, 255, 255))
                                    if img.mode == "P":
                                        img = img.convert("RGBA")
                                    rgb_img.paste(img, mask=img.split()[-1] if img.mode in ("RGBA", "LA") else None)
                                    converted_img = rgb_img
                                elif img.mode != "RGB":
                                    logger.info("üîÑ Converting {} mode to RGB", img.mode)
                                    converted_img = img.convert("RGB")
                                else:
                                    logger.info("‚úÖ Image already in RGB mode, copying")
                                    converted_img = img.copy()
                                
                                logger.info("üíæ Saving PNG file to: {}", png_path)
                                # Save PNG file
                                try:
                                    converted_img.save(png_path, "PNG", optimize=False)
                                    logger.info("‚úÖ PNG file saved successfully")
                                except Exception as save_exc:  # noqa: BLE001
                                    logger.error("‚ùå Failed to save PNG file: {}", save_exc, exc_info=True)
                                    raise
                            
                            # Remove original webp file
                            logger.info("üóëÔ∏è Removing original webp file: {}", download_path)
                            download_path.unlink()
                            final_path = png_path
                            png_size = png_path.stat().st_size
                            logger.info("‚úÖ Converted to PNG: {} bytes ({:.2f} KB) saved to {}", 
                                       png_size, png_size / 1024, png_path)
                    except Exception as conv_exc:  # noqa: BLE001
                        logger.error("‚ö†Ô∏è Failed to convert webp to PNG: {}, keeping original webp", conv_exc, exc_info=True)

                # Update job metadata
                redis_job = get_job(job_id)
                if redis_job:
                    meta = redis_job.meta or {}
                    meta["result_path"] = final_path.as_posix()
                    redis_job.meta = meta
                    redis_job.save_meta()
            else:
                logger.warning("‚ùå ASYNC DOWNLOAD: file does not exist after download: {}", download_path)
        except Exception as exc:  # noqa: BLE001
            logger.warning("‚ùå ASYNC DOWNLOAD FAILED for job {}: {}", job_id, exc, exc_info=True)

    logger.info("üîÑ SCHEDULING async download for job {} (background thread)", job_id)
    threading.Thread(
        target=_worker,
        name=f"fal-download-{job_id}",
        daemon=True,
    ).start()


def _send_success_notification_sync(
    notify: dict[str, Any],
    job_id: str,
    image_url: str | None = None,
    image_bytes: bytes | None = None,
    filename: str | None = None,
    caption_title: str = "üñºÔ∏è –ì–æ—Ç–æ–≤–æ!",
    reply_markup: InlineKeyboardMarkup | None = None,
) -> None:
    """Send success notification synchronously (for use in workers)."""
    from app.core.telegram_sync import send_document_sync

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±–µ–∑ –ø—Ä–æ–º–ø—Ç–∞
    caption = caption_title

    # Convert reply_markup to dict if needed
    reply_markup_dict = None
    if reply_markup:
        reply_markup_dict = reply_markup.model_dump() if hasattr(reply_markup, 'model_dump') else None

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º message_id –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
    sent_message_id = None

    if image_bytes is not None:
        file_size_kb = len(image_bytes) / 1024
        logger.info("Sending image as bytes: size = {:.2f} KB ({} bytes), filename = {}", 
                   file_size_kb, len(image_bytes), filename or "image.png")
        sent_message_id = send_document_sync(
            chat_id=notify["chat_id"],
            document=image_bytes,
            filename=filename or "image.png",
            caption=caption,
            reply_to_message_id=notify.get("reply_to_message_id"),
            message_thread_id=notify.get("message_thread_id"),
            reply_markup=reply_markup_dict,
        )
    elif image_url:
        # –î–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ URL –Ω–∞–ø—Ä—è–º—É—é
        # –≠—Ç–æ –∏–∑–±–µ–≥–∞–µ—Ç –¥–≤–æ–π–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è - –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
        # Telegram —Å–∫–∞—á–∞–µ—Ç —Ñ–∞–π–ª —Å–∞–º, –∞ –º—ã –∫–µ—à–∏—Ä—É–µ–º –µ–≥–æ –≤ —Ñ–æ–Ω–µ –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        logger.info("üì§ Sending by URL directly (async download in background, Telegram will download): {}", image_url[:100])
        sent_message_id = send_document_sync(
            chat_id=notify["chat_id"],
            document=image_url,
            caption=caption,
            reply_to_message_id=notify.get("reply_to_message_id"),
            message_thread_id=notify.get("message_thread_id"),
            reply_markup=reply_markup_dict,
        )

    # –ü—Ä–æ–º–ø—Ç –±–æ–ª—å—à–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º - —Ç–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ caption


def _send_failure_notification_sync(notify: dict[str, Any], job_id: str, error: str) -> None:
    """Send failure notification synchronously (for use in workers)."""
    from app.core.telegram_sync import send_message_sync

    text = f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–¥–∞—á—É {job_id}.\n–û—à–∏–±–∫–∞: {error}"
    send_message_sync(
        chat_id=notify["chat_id"],
        text=text,
        reply_to_message_id=notify.get("reply_to_message_id"),
        message_thread_id=notify.get("message_thread_id"),
    )


def _is_network_error(exc: Exception) -> bool:
    return isinstance(exc, httpx.RequestError)


def _parse_operation_id(operation_id_raw: Any, job_id: str, context: str = "") -> int | None:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç operation_id –≤ int, —Ç–∞–∫ –∫–∞–∫ —á–µ—Ä–µ–∑ RQ –æ–Ω –º–æ–∂–µ—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞.
    
    Args:
        operation_id_raw: –°—ã—Ä–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ operation_id
        job_id: ID –∑–∞–¥–∞—á–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "image", "face_swap")
        
    Returns:
        int | None: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π operation_id –∏–ª–∏ None
    """
    if operation_id_raw is None:
        return None
    
    try:
        operation_id = int(operation_id_raw)
        if operation_id:
            logger.debug("{} job {}: extracted operation_id={} (type: {})", 
                        context or "Job", job_id, operation_id, type(operation_id_raw).__name__)
        return operation_id
    except (ValueError, TypeError) as e:
        logger.warning("{} job {}: failed to convert operation_id '{}' to int: {}", 
                      context or "Job", job_id, operation_id_raw, e)
        return None


def _is_retryable_error(exc: Exception) -> bool:
    """Check if error is retryable (network errors or server errors 500-503)"""
    if isinstance(exc, httpx.RequestError):
        logger.debug("Error is retryable (RequestError): {}", type(exc).__name__)
        return True
    if isinstance(exc, httpx.HTTPStatusError):
        status_code = exc.response.status_code
        is_retryable = status_code in (500, 502, 503)
        logger.info("HTTPStatusError with status {}: retryable={}", status_code, is_retryable)
        if is_retryable:
            return True
    logger.debug("Error is NOT retryable: {} ({})", type(exc).__name__, exc)
    return False


def process_face_swap_job(
    job_id: str,
    source_path: str,
    target_path: str,
    instruction: str | None,
    options: dict | None,
    output_path: str,
) -> str:
    # Import models to ensure they are registered with Base.metadata
    from app.db import models  # noqa: F401
    from app.services.billing import BillingService
    from app.db.base import SessionLocal

    provider_options: Dict[str, Any] = dict(options or {})
    operation_id_raw = provider_options.pop("operation_id", None)
    operation_id = _parse_operation_id(operation_id_raw, job_id, "Face swap")
    logger.info("Face swap job {}: operation_id_raw={} (type: {}), parsed operation_id={}", 
               job_id, operation_id_raw, type(operation_id_raw).__name__ if operation_id_raw is not None else "None", operation_id)
    provider_instruction = provider_options.pop("provider_instruction", None)
    model_name = provider_options.pop("model", FACE_SWAP_DEFAULT_MODEL) or FACE_SWAP_DEFAULT_MODEL
    logger.info("Face swap job {}: model_name from options: '{}' (default: '{}')", 
               job_id, model_name, FACE_SWAP_DEFAULT_MODEL)

    # Always translate instruction to English if it's not already translated
    # Use provider_instruction if available (already translated), otherwise translate instruction
    from app.utils.translation import translate_to_english
    if provider_instruction:
        # Already translated
        final_prompt = provider_instruction
    elif instruction:
        # Translate to English
        final_prompt = translate_to_english(instruction)
        logger.info("Face swap job {}: translated instruction '{}' -> '{}'", job_id, instruction[:100], final_prompt[:100] if final_prompt else "none")
    else:
        final_prompt = None

    notify_options = _extract_notify_options(provider_options)
    output_file = Path(output_path)
    source_file = Path(source_path)
    target_file = Path(target_path)

    job = get_current_job()

    try:
        if job:
            job.meta.update(
                {
                    "face_swap": True,
                    "prompt": instruction or "–ó–∞–º–µ–Ω–∞ –ª–∏—Ü–∞",
                    "source_path": source_file.as_posix(),
                    "target_path": target_file.as_posix(),
                }
            )
            if provider_instruction and provider_instruction != (instruction or ""):
                job.meta["provider_instruction"] = provider_instruction
            job.save_meta()

        if not source_file.exists():
            error = f"Source face image not found at {source_path}"
            logger.error("Face swap job {} missing source image: {}", job_id, source_path)
            if job:
                job.meta["error"] = error
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, error)
            raise RuntimeError(error)

        if not target_file.exists():
            error = f"Target image not found at {target_path}"
            logger.error("Face swap job {} missing target image: {}", job_id, target_path)
            if job:
                job.meta["error"] = error
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, error)
            raise RuntimeError(error)

        logger.info(
            "Processing face swap job {} (source={}, target={}, instruction={})",
            job_id,
            source_path,
            target_path,
            instruction or "none",
        )

        # Check if this is advanced face swap model - use WaveSpeedAI
        # Advanced models use WaveSpeedAI API (not Fal.ai)
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        from app.core.config import reload_settings
        current_settings = reload_settings()
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        logger.debug("Face swap job {}: wavespeed_api_key from env: {}, from settings: {}", 
                    job_id, os.getenv("WAVESPEED_API_KEY"), current_settings.wavespeed_api_key)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å WaveSpeedAI –º–æ–¥–µ–ª—å—é (akool, wavespeed-ai, head-swap –∏ —Ç.–¥.)
        is_advanced_model = (
            "codeplugtech" in model_name.lower() or
            "cdingram" in model_name.lower() or
            "advanced-face-swap" in model_name.lower() or
            "advanced" in model_name.lower() or
            "akool" in model_name.lower() or  # akool/image-face-swap
            "wavespeed-ai" in model_name.lower() or  # wavespeed-ai/image-face-swap, image-head-swap
            "head-swap" in model_name.lower() or  # wavespeed-ai/image-head-swap
            model_name == current_settings.wavespeed_face_swap_model  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
        )
        logger.info("Face swap job {}: model_name='{}', is_advanced_model={}, wavespeed_model={}", 
                    job_id, model_name, is_advanced_model, current_settings.wavespeed_face_swap_model)

        if is_advanced_model:
            # Use WaveSpeedAI for advanced face swap
            if not WAVESPEED_AVAILABLE:
                error_msg = "WaveSpeedAI –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É httpx."
                logger.error("Face swap job {}: WaveSpeedAI not available", job_id)
                if job:
                    job.meta["error"] = error_msg
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, error_msg)
                raise RuntimeError(error_msg)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–∞–ø—Ä—è–º—É—é, –µ—Å–ª–∏ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –µ–≥–æ –Ω–µ—Ç
            wavespeed_api_key = current_settings.wavespeed_api_key or os.getenv("WAVESPEED_API_KEY")
            if not wavespeed_api_key:
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å Fal.ai, –µ—Å–ª–∏ –∫–ª—é—á WaveSpeedAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω
                logger.warning("Face swap job {}: WaveSpeedAI API key not configured (env: {}, settings: {}), falling back to Fal.ai model", 
                            job_id, os.getenv("WAVESPEED_API_KEY"), current_settings.wavespeed_api_key)
                logger.info("Face swap job {}: Switching from WaveSpeedAI model '{}' to Fal.ai model '{}'", 
                           job_id, model_name, current_settings.fal_face_swap_model)
                # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
                model_name = current_settings.fal_face_swap_model
                is_advanced_model = False
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é Fal.ai

            logger.info("Face swap job {} using WaveSpeedAI for advanced model", job_id)
            try:
                # –ü–µ—Ä–µ–¥–∞–µ–º –º–æ–¥–µ–ª—å —è–≤–Ω–æ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
                # wavespeed_face_swap —Å–∞–º–∞ –∑–∞–≥—Ä—É–∂–∞–µ—Ç API –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
                result_url = wavespeed_face_swap(
                    source_path=target_file.as_posix(),  # target - –∫—É–¥–∞ –≤—Å—Ç–∞–≤–ª—è–µ–º –ª–∏—Ü–æ
                    face_path=source_file.as_posix(),   # source - –æ—Ç–∫—É–¥–∞ –±–µ—Ä–µ–º –ª–∏—Ü–æ
                    model=current_settings.wavespeed_face_swap_model,  # –Ø–≤–Ω–æ –ø–µ—Ä–µ–¥–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
                )
                logger.info("Face swap job {} successfully completed via WaveSpeedAI: {}", job_id, result_url[:50])
                # –°–∫–∞—á–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ PNG (API –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å PNG –±–ª–∞–≥–æ–¥–∞—Ä—è –ø–∞—Ä–∞–º–µ—Ç—Ä—É output_format)
                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ output_file –∏–º–µ–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .png
                if output_file.suffix.lower() != ".png":
                    output_file = output_file.with_suffix(".png")
                    logger.debug("Face swap job {}: ensuring output file has .png extension: {}", job_id, output_file)
                
                _download_file_with_retry(result_url, output_file.as_posix())
                logger.info("Face swap job {}: downloaded result as PNG ({} bytes)", job_id, output_file.stat().st_size if output_file.exists() else 0)

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ Telegram
                if notify_options.get("chat_id"):
                    try:
                        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
                        with open(output_file, "rb") as f:
                            image_bytes = f.read()
                        logger.info("Face swap job {}: sending notification with image bytes ({} bytes)", job_id, len(image_bytes))
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
                        filename = output_file.name
                        _send_success_notification_sync(
                            notify_options,
                            job_id,
                            image_bytes=image_bytes,
                            filename=filename,
                            caption_title="ü§ñ –ó–∞–º–µ–Ω–∞ –ª–∏—Ü–∞ –≥–æ—Ç–æ–≤–∞!",
                        )
                    except Exception as notify_error:
                        logger.error("Failed to send Telegram notification for face swap job {}: {}", job_id, notify_error)

                # Confirm operation after successful completion (WaveSpeedAI path)
                if operation_id:
                    db = SessionLocal()
                    try:
                        success = BillingService.confirm_operation(db, operation_id)
                        if success:
                            logger.info("Confirmed operation {} for face swap job {} (WaveSpeedAI)", operation_id, job_id)
                        else:
                            logger.error("Failed to confirm operation {} for face swap job {} (WaveSpeedAI)", operation_id, job_id)
                    except Exception as e:
                        logger.error("Error confirming operation {} for face swap job {} (WaveSpeedAI): {}", operation_id, job_id, e, exc_info=True)
                    finally:
                        db.close()

                return output_file.as_posix()
            except Exception as wavespeed_exc:
                logger.error("Face swap job {} WaveSpeedAI failed: {}", job_id, wavespeed_exc)
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–µ—Ä–µ–∑ WaveSpeedAI: {str(wavespeed_exc)}"
                if job:
                    job.meta["error"] = str(wavespeed_exc)
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, error_msg)
                raise RuntimeError(error_msg) from wavespeed_exc

        # For basic models, use Fal.ai as before
        # Remove any incorrect values that might be in provider_options
        clean_options = dict(provider_options)
        # Remove model from clean_options to avoid conflicts - we pass it explicitly
        if "model" in clean_options:
            clean_options.pop("model")
        # Remove invalid gender_0 and workflow_type values - they will be set correctly in submit_face_swap
        if "gender_0" in clean_options and clean_options["gender_0"] not in ("male", "female", "non-binary"):
            clean_options.pop("gender_0")
        if "workflow_type" in clean_options and clean_options["workflow_type"] not in ("user_hair", "target_hair"):
            clean_options.pop("workflow_type")

        # Use queue API for more reliable processing
        attempts = 0
        delay = FACE_SWAP_RETRY_BASE_DELAY
        last_error: Exception | None = None
        task_id: str | None = None

        logger.info("Face swap job {}: submitting to Fal.ai with model='{}' (is_advanced_model={})", 
                   job_id, model_name, False)
        while attempts < FACE_SWAP_MAX_ATTEMPTS:
            try:
                task_id = submit_face_swap(
                    source_path=source_file.as_posix(),
                    target_path=target_file.as_posix(),
                    prompt=final_prompt,
                    model=model_name,
                    **clean_options,
                )
                logger.info("Face swap job {} submitted to queue with task_id: {}", job_id, task_id)
                break
            except Exception as exc:  # noqa: BLE001
                last_error = exc
                attempts += 1
                logger.info("Face swap job {} submit attempt {} caught exception: {} ({})", 
                           job_id, attempts, type(exc).__name__, exc)
            is_retryable = _is_retryable_error(exc)
            logger.info("Face swap job {} submit attempt {}: is_retryable={}, attempts_left={}", 
                       job_id, attempts, is_retryable, FACE_SWAP_MAX_ATTEMPTS - attempts)
            if is_retryable and attempts < FACE_SWAP_MAX_ATTEMPTS:
                error_type = "network/server" if isinstance(exc, (httpx.RequestError, httpx.HTTPStatusError)) else "error"
                logger.warning(
                    "Face swap job {} submit attempt {} failed due to {} issue: {}. Retrying in {:.1f}s",
                    job_id,
                    attempts,
                    error_type,
                    exc,
                    delay,
                )
                time.sleep(delay)
                delay *= 2
                continue
            logger.error("Face swap job {} submit failed after {} attempts: {}", job_id, attempts, exc)

            # Determine error message based on error type
            if isinstance(exc, httpx.HTTPStatusError):
                status_code = exc.response.status_code
                if status_code == 500:
                    error_msg = (
                        "–°–µ—Ä–≤–µ—Ä –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–æ—à–∏–±–∫–∞ 500). "
                        "–≠—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ —Å–µ—Ä–≤–∏—Å–∞ fal.ai. "
                        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."
                    )
                elif status_code == 422:
                    error_msg = (
                        "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ (–æ—à–∏–±–∫–∞ 422). "
                        "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ª–∏—Ü–∞–º–∏."
                    )
                elif status_code == 429:
                    error_msg = (
                        "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ—à–∏–±–∫–∞ 429). "
                        "–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
                    )
                else:
                    error_msg = f"–û—à–∏–±–∫–∞ API (–∫–æ–¥ {status_code}). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            elif isinstance(exc, httpx.RequestError):
                error_msg = (
                    "–ü—Ä–æ–±–ª–µ–º–∞ —Å —Å–µ—Ç—å—é –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API. "
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
                )
            else:
                error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞ –∑–∞–º–µ–Ω—É –ª–∏—Ü–∞: {str(exc)}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

            if job:
                job.meta["error"] = str(exc)
                job.meta["error_message"] = error_msg
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(
                    notify_options,
                    job_id,
                    error_msg,
                )
                raise

        if task_id is None:
            error = last_error or RuntimeError("Face swap task submission failed")
            if job:
                job.meta["error"] = str(error)
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, str(error))
            raise RuntimeError(str(error))

        # Poll for completion using queue API
        logger.info("Face swap job {} polling for task {} completion", job_id, task_id)
        status = check_image_status(task_id)
        max_poll_attempts = 60  # 5 minutes max (60 * 5 seconds)
        poll_attempts = 0

        while status["status"] not in ("succeeded", "failed"):
            if poll_attempts >= max_poll_attempts:
                error = "Face swap task timed out after polling"
                logger.error("Face swap job {} task {} timed out", job_id, task_id)
                if job:
                    job.meta["error"] = error
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, "–ó–∞–¥–∞—á–∞ –ø—Ä–µ–≤—ã—Å–∏–ª–∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                raise RuntimeError(error)

            poll_attempts += 1
            time.sleep(5)  # Poll every 5 seconds
            status = check_image_status(task_id)
            logger.debug("Face swap job {} task {} status: {}", job_id, task_id, status["status"])

        if status["status"] == "failed":
            error = status.get("error", "Unknown error")
            logger.error("Face swap job {} task {} failed: {}", job_id, task_id, error)
            if job:
                job.meta["error"] = error
                job.save_meta()
            if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, f"–ó–∞–º–µ–Ω–∞ –ª–∏—Ü–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {error}")
            raise RuntimeError(error)

        # According to fal.ai docs, when status is COMPLETED, the result may be in the status response itself
        # or available via response_url. Let's check if result is already in status first.
        # Import the helper function to extract image URL from response
        from app.providers.fal.images import _extract_image_url as extract_image_url
        status_image_url = extract_image_url(status)
        logger.debug("Face swap job {} extracted URL from status: {}", job_id, status_image_url[:100] if status_image_url else "None")
        asset = None

        if status_image_url:
            # Check if this is a queue API endpoint (response_url) or a real image URL
            if status_image_url.startswith("https://queue.fal.run") or status_image_url.startswith("http://queue.fal.run"):
                # This is a queue API endpoint, not a direct image URL - skip it
                logger.info("Face swap job {} found response_url in status (not a direct image URL), will use resolve_image_asset", job_id)
                status_image_url = None
                asset = None  # Ensure asset is None so we use resolve_image_asset
            elif status_image_url.startswith("data:"):
                logger.info("Face swap job {} result found in status response (data URL)", job_id)
                # Result is already in status as data URL, extract it directly
                from app.providers.fal.images import ImageAsset
                import base64
                header, _, data_part = status_image_url.partition(",")
                content = base64.b64decode(data_part)
                asset = ImageAsset(url=None, content=content, filename="face-swap.png")
            elif status_image_url.startswith("http"):
                # This looks like a direct image URL (CDN, etc.)
                logger.info("Face swap job {} result found in status response (direct URL): {}", job_id, status_image_url[:100])
                from app.providers.fal.images import ImageAsset
                asset = ImageAsset(url=status_image_url, content=None, filename=None)
            else:
                logger.warning("Face swap job {} unexpected image URL format in status: {}", job_id, status_image_url[:100])

        # If result not in status, try to get it via response_url with retries
        if asset is None:
            result_url = status.get("result_url")
            if not result_url:
                error = "Face swap task completed but no result URL provided and no result in status"
                logger.error("Face swap job {} task {} completed without result URL or result in status", job_id, task_id)
                if job:
                    job.meta["error"] = error
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, "–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
                raise RuntimeError(error)

        # Small delay after completion to allow API to prepare the result
        # Sometimes the API returns 500 immediately after COMPLETED status
        logger.debug("Face swap job {} task {} completed, waiting 1s before fetching result", job_id, task_id)
        time.sleep(1.0)

        # Try to get result with retries and increasing delays
        # Use resolve_image_asset which properly handles authorization and retries
        max_result_attempts = 5
        result_delay = 1.0
        last_result_error: Exception | None = None

        for result_attempt in range(max_result_attempts):
            try:
                logger.debug("Face swap job {} attempt {} to get result from {}", job_id, result_attempt + 1, result_url)
                # Use resolve_image_asset which properly handles queue API authorization
                asset = resolve_image_asset(result_url)
                logger.info("Face swap job {} successfully got result on attempt {}: asset.url={}, asset.content={}", 
                           job_id, result_attempt + 1, asset.url[:100] if asset.url else "None", asset.content is not None)
                # Check if asset.url is a queue API endpoint - if so, we need to get the actual image URL
                if asset.url and (asset.url.startswith("https://queue.fal.run") or asset.url.startswith("http://queue.fal.run")):
                    logger.warning("Face swap job {} asset.url is a queue API endpoint, this should not happen. asset.url={}", 
                                  job_id, asset.url)
                    # Try to get the actual result from queue_result
                    from app.providers.fal.client import queue_result
                    from app.providers.fal.images import _extract_image_url, ImageAsset, _parse_result_url
                    parsed = _parse_result_url(result_url)
                    if parsed:
                        model_path, request_id = parsed
                        logger.info("Face swap job {} trying queue_result directly for model={}, request_id={}", 
                                   job_id, model_path, request_id)
                        response_data = queue_result(model_path, request_id)
                        logger.info("Face swap job {} queue_result response keys: {}", job_id, list(response_data.keys()) if isinstance(response_data, dict) else "not a dict")
                        actual_image_url = _extract_image_url(response_data)
                        if actual_image_url and not (actual_image_url.startswith("https://queue.fal.run") or actual_image_url.startswith("http://queue.fal.run")):
                            logger.info("Face swap job {} extracted actual image URL: {}", job_id, actual_image_url[:100])
                            asset = ImageAsset(url=actual_image_url, content=None, filename=None)
                        else:
                            logger.error("Face swap job {} failed to extract valid image URL from queue_result response", job_id)
                break
            except httpx.HTTPStatusError as exc:
                last_result_error = exc
                status_code = exc.response.status_code
                if status_code in (500, 502, 503, 401) and result_attempt < max_result_attempts - 1:
                    logger.warning(
                        "Face swap job {} result attempt {} failed with {}: {}. Retrying in {:.1f}s",
                        job_id,
                        result_attempt + 1,
                        status_code,
                        exc.response.text[:100] if hasattr(exc.response, 'text') else str(exc),
                        result_delay,
                    )
                    time.sleep(result_delay)
                    result_delay *= 1.5
                    continue
                else:
                    logger.error("Face swap job {} result attempt {} failed with {}: {}", job_id, result_attempt + 1, status_code, exc)
                    raise
            except Exception as exc:  # noqa: BLE001
                last_result_error = exc
                logger.error("Face swap job {} result attempt {} failed: {}", job_id, result_attempt + 1, exc)
                if result_attempt >= max_result_attempts - 1:
                    raise

        if asset is None:
            error = last_result_error or RuntimeError("Failed to get face swap result")
            logger.error("Face swap job {} failed to get result after {} attempts: {}", job_id, max_result_attempts, error)

            # Create user-friendly error message
            error_str = str(error)
            if "timeout" in error_str.lower() or "timed out" in error_str.lower():
                user_error_msg = (
                    "‚Ä¢ –ü—Ä–æ–±–ª–µ–º–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ —Å–µ—Ä–≤–∏—Å–∞\n\n"
                    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
                    "‚Ä¢ –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç\n"
                    "‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å Face Swap (fal-ai/face-swap)"
                )
            elif "500" in error_str:
                user_error_msg = (
                    "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ API Fal.ai (500 Internal Server Error).\n\n"
                    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."
                )
            else:
                user_error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {error_str}"

            if job:
                job.meta["error"] = error_str
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, user_error_msg)
            raise RuntimeError(error_str)

        # Try to persist asset locally, but don't block on it
        # If asset has content, save it immediately
        saved_path = None
        image_bytes = asset.content
        filename = asset.filename

        if image_bytes:
            # We have content, save it immediately
            try:
                output_file.parent.mkdir(parents=True, exist_ok=True)
                output_file.write_bytes(image_bytes)
                saved_path = output_file
                filename = filename or output_file.name
            except Exception as exc:  # noqa: BLE001
                logger.warning("Face swap job {}: failed to save inline bytes: {}", job_id, exc)
        elif asset.url:
            # We only have URL - schedule background download for caching
            # but don't try to download synchronously as it may timeout
            # Telegram can download the image directly from the URL
            _schedule_result_download(job_id, asset.url, output_file)
            logger.info("Face swap job {}: will send image by URL (background download scheduled): {}", job_id, asset.url[:100])
            # Continue without local file - we'll send by URL

        if job:
            job.meta["image_url"] = asset.url
            if image_bytes:
                job.meta["image_inline"] = True
                if filename:
                    job.meta["image_filename"] = filename
            if saved_path:
                job.meta["result_path"] = saved_path.as_posix()
            else:
                job.meta["result_path"] = None
            job.save_meta()

        caption_path = saved_path.as_posix() if saved_path else asset.url or ""
        logger.success("Face swap job {} completed: {}", job_id, caption_path)

        if notify_options.get("chat_id"):
            logger.info("Face swap job {}: preparing notification (image_bytes={}, saved_path={}, asset.url={})", 
                        job_id, image_bytes is not None, saved_path, asset.url[:100] if asset.url else None)
            try:
                if image_bytes is None and saved_path and saved_path.exists():
                    image_bytes = saved_path.read_bytes()
                    filename = filename or saved_path.name
                    logger.info("Face swap job {}: loaded image bytes from saved file ({} bytes)", job_id, len(image_bytes))
            except Exception as exc:  # noqa: BLE001
                logger.warning("Face swap job {}: failed to prepare bytes for notification: {}", job_id, exc)

            if image_bytes is not None:
                logger.info("Face swap job {}: sending notification with image bytes ({} bytes)", job_id, len(image_bytes))
                try:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_bytes=image_bytes,
                        filename=filename or "face-swap.png",
                        caption_title="ü§ñ –ó–∞–º–µ–Ω–∞ –ª–∏—Ü–∞ –≥–æ—Ç–æ–≤–∞!",
                        reply_markup=None,
                    )
                    logger.info("Face swap job {}: successfully sent notification with image bytes", job_id)
                except Exception as notify_error:  # noqa: BLE001
                    logger.error("Failed to send Telegram notification for face swap job {}: {}", job_id, notify_error)
            elif asset.url:
                # Fallback to sending the URL if bytes are unavailable
                logger.info("Face swap job {}: sending notification with image URL: {}", job_id, asset.url[:100])
                try:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_url=asset.url,
                        caption_title="ü§ñ –ó–∞–º–µ–Ω–∞ –ª–∏—Ü–∞ –≥–æ—Ç–æ–≤–∞!",
                        reply_markup=None,
                    )
                    logger.info("Face swap job {}: successfully sent notification with image URL", job_id)
                except Exception as notify_error:  # noqa: BLE001
                    logger.error("Failed to send fallback notification for face swap job {}: {}", job_id, notify_error)
            else:
                logger.error("Face swap job {}: cannot send notification - no image_bytes and no asset.url", job_id)

        # Confirm operation after successful completion
        if operation_id:
            db = SessionLocal()
            try:
                success = BillingService.confirm_operation(db, operation_id)
                if success:
                    logger.info("Confirmed operation {} for face swap job {}", operation_id, job_id)
                else:
                    logger.error("Failed to confirm operation {} for face swap job {}", operation_id, job_id)
            except Exception as e:
                logger.error("Error confirming operation {} for face swap job {}: {}", operation_id, job_id, e, exc_info=True)
            finally:
                db.close()

        return caption_path
    except JobTimeoutException as timeout_exc:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –∑–∞–¥–∞—á–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        logger.error("Face swap job {} timed out after 4 minutes", job_id)
        _handle_job_timeout(job_id, notify_options, "–∑–∞–º–µ–Ω—ã –ª–∏—Ü–∞")
        # Mark operation as failed
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for face swap job {} due to timeout", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for face swap job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise
    except Exception as e:
        # Mark operation as failed on any error
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for face swap job {} due to error", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for face swap job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise


def _enhance_flux2flex_prompt_for_cyrillic(prompt: str) -> str:
    """
    –£–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è Flux 2 Flex –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã.
    –î–æ–±–∞–≤–ª—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è —á–µ—Ç–∫–æ–≥–æ –∏ —á–∏—Ç–∞–µ–º–æ–≥–æ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ –ø—Ä–æ–º–ø—Ç–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ —Ç–µ–∫—Å—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
    has_russian_text_instruction = any(keyword in prompt.lower() for keyword in [
        '—Ç–µ–∫—Å—Ç', '–Ω–∞–¥–ø–∏—Å—å', '–Ω–∞–ø–∏—Å–∞–Ω–æ', '—à—Ä–∏—Ñ—Ç', '–±—É–∫–≤—ã', '–Ω–∞–¥–ø–∏—Å–∏', '–Ω–∞–¥–ø–∏—Å—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º',
        '—Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ', '–Ω–∞ —Ä—É—Å—Å–∫–æ–º', '–∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π', '–∫–∏—Ä–∏–ª–ª–∏—Ü–∞'
    ])
    
    if not has_russian_text_instruction:
        # –ï—Å–ª–∏ –≤ –ø—Ä–æ–º–ø—Ç–µ –Ω–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –æ —Ç–µ–∫—Å—Ç–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return prompt
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    enhancement = (
        "\n\n–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: "
        "–í—Å–µ –Ω–∞–¥–ø–∏—Å–∏ –∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å: "
        "–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —á–µ—Ç–∫–∏–º–∏ –∏ —Ä–µ–∑–∫–∏–º–∏ (sharp, crisp), "
        "–ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–∑–±–æ—Ä—á–∏–≤—ã–º–∏ (fully legible), "
        "—Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç–æ–º (very high contrast), "
        "—Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–º–∏ –±—É–∫–≤–∞–º–∏ –±–µ–∑ –∏—Å–∫–∞–∂–µ–Ω–∏–π (correct Cyrillic letters without distortions), "
        "—Ö–æ—Ä–æ—à–æ —á–∏—Ç–∞–µ–º—ã–º–∏ (highly readable), "
        "–≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Ñ–æ–∫—É—Å–µ (perfect focus), "
        "—Å —á–µ—Ç–∫–∏–º–∏ –∏ —Ä–µ–∑–∫–∏–º–∏ –∫—Ä–∞—è–º–∏ –±—É–∫–≤ (sharp letter edges), "
        "–±–µ–∑ —Ä–∞–∑–º—ã—Ç–∏—è (no blur), "
        "–±–µ–∑ –æ–ø–µ—á–∞—Ç–æ–∫ (no typos), "
        "–±–µ–∑ –∑–∞–º–µ–Ω—ã –±—É–∫–≤ (no letter substitutions), "
        "—Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π (correct Cyrillic alphabet). "
        "–¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∏–∑—É–∞–ª—å–Ω–æ –≤—ã–¥–µ–ª–µ–Ω (visually prominent), "
        "–∏–º–µ—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è (adequate size for comfortable reading), "
        "–∏–º–µ—Ç—å –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–π —Ñ–æ–Ω –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ (contrasting background for maximum legibility), "
        "–∫–∞–∂–¥–∞—è –±—É–∫–≤–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —á–µ—Ç–∫–æ —Ä–∞–∑–ª–∏—á–∏–º–∞ (each letter must be clearly distinguishable)."
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º —É–ª—É—á—à–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç –≤ –ø—Ä–æ–º–ø—Ç–µ
    if "–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —á–µ—Ç–∫–∏–º–∏" not in prompt.lower() and "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ" not in prompt.lower():
        return prompt + enhancement
    
    return prompt


def process_image_job(job_id: str, prompt: str, options: dict | None, output_path: str) -> str:
    # Import models to ensure they are registered with Base.metadata
    from app.db import models  # noqa: F401
    from app.services.billing import BillingService
    from app.db.base import SessionLocal

    provider_options: Dict[str, Any] = dict(options or {})
    logger.info("Image job {}: received options keys: {}", job_id, list(provider_options.keys()))
    operation_id_raw = provider_options.pop("operation_id", None)
    logger.info("Image job {}: operation_id_raw from options: {} (type: {})", 
               job_id, operation_id_raw, type(operation_id_raw).__name__ if operation_id_raw is not None else "None")
    operation_id = _parse_operation_id(operation_id_raw, job_id, "Image")
    
    # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å –ü–ï–†–ï–î –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º provider_prompt, —á—Ç–æ–±—ã —Å—Ä–∞–∑—É —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    model_name = provider_options.get("model", "")
    selected_model = provider_options.get("selected_model", "")
    is_nano_banana = model_name == "fal-ai/nano-banana" or model_name == "fal-ai/nano-banana-pro" or "nano-banana" in model_name.lower()
    is_flux2flex = "flux-2-flex" in model_name.lower() or selected_model == "flux2flex-create"
    
    # –î–ª—è Nano Banana, Flux 2 Flex –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä—É—Å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –ë–ï–ó –ø–µ—Ä–µ–≤–æ–¥–∞
    if is_nano_banana or is_flux2flex:
        provider_prompt = prompt  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä—É—Å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
        if is_nano_banana:
            logger.info("Image job {}: Nano-banana model detected, using original Russian prompt without translation", job_id)
        elif is_flux2flex:
            logger.info("Image job {}: Flux 2 Flex model detected, using original Russian prompt without translation", job_id)
            # –£–ª—É—á—à–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Flux 2 Flex –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
            provider_prompt = _enhance_flux2flex_prompt_for_cyrillic(prompt)
            logger.info("Image job {}: Enhanced Flux 2 Flex prompt for better Cyrillic text generation", job_id)
    else:
        # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π –∏–∑–≤–ª–µ–∫–∞–µ–º provider_prompt –∏–∑ options (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω –≤ –±–æ—Ç–µ)
        provider_prompt = provider_options.pop("provider_prompt", prompt)
    
    output_file = Path(output_path)
    job = get_current_job()
    if job:
        job.meta.update({"prompt": prompt})
        if prompt != provider_prompt:
            job.meta["provider_prompt"] = provider_prompt
        job.save_meta()

    notify_options = _extract_notify_options(provider_options)

    try:
        logger.info("Processing image job {} with prompt '{}'", job_id, prompt[:100])
        logger.info("Image job {}: provider_prompt='{}' (same as prompt: {})", 
                    job_id, provider_prompt[:100] if provider_prompt else "None", provider_prompt == prompt)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å Nano Banana Pro (gpt-create - –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∫–ª—é—á –¥–ª—è UI)
        selected_model = provider_options.get("selected_model", "")
        is_gpt_create = selected_model == "gpt-create"

        if is_gpt_create:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Nano Banana Pro —á–µ—Ä–µ–∑ Fal.ai –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
            logger.info("Image job {} using Nano Banana Pro (Fal.ai) for text-to-image generation", job_id)

            # Nano Banana Pro –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É –Ω–∞–ø—Ä—è–º—É—é, –Ω–µ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            provider_prompt = prompt

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å Nano Banana Pro (—É–∂–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
            provider_options["model"] = "fal-ai/nano-banana-pro"
            provider_options["selected_model"] = None  # –£–±–∏—Ä–∞–µ–º gpt-create, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—ã—á–Ω—É—é –ª–æ–≥–∏–∫—É

            logger.info("Image job {}: Using Nano Banana Pro with original Russian prompt: '{}'", job_id, prompt[:50])

        # –í–ê–ñ–ù–û: –î–ª—è –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç —Ä—É—Å—Å–∫–∏–π (Nano Banana, Flux 2 Flex),
        # provider_prompt —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ —Ä—É—Å—Å–∫–æ–º –≤–∞—Ä–∏–∞–Ω—Ç–µ –≤—ã—à–µ, –ù–ï –ü–ï–†–ï–í–û–î–ò–ú!
        # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å
        if not (is_nano_banana or is_flux2flex):
            if provider_prompt != prompt:
                logger.info("Using translated prompt for job {}: '{}'", job_id, provider_prompt[:100])
            else:
                # –ï—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø–æ–ø—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –∑–¥–µ—Å—å –µ—â–µ —Ä–∞–∑
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –ø—Ä–æ–º–ø—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É (–ø—Ä–∏–∑–Ω–∞–∫ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞)
                has_cyrillic = any('\u0400' <= char <= '\u04FF' for char in prompt)
                logger.info("Image job {}: checking for Cyrillic in prompt: {}", job_id, has_cyrillic)
                if has_cyrillic:
                    logger.warning("Image job {}: provider_prompt is same as original (likely Russian), attempting translation in worker", job_id)
                    try:
                        translated = translate_to_english(prompt)
                        if translated != prompt and translated:
                            logger.info("Image job {}: successfully translated in worker: '{}' -> '{}'", 
                                       job_id, prompt[:50], translated[:50])
                            provider_prompt = translated
                        else:
                            logger.warning("Image job {}: translation in worker failed or returned same text, using original", job_id)
                    except Exception as exc:
                        logger.error("Image job {}: translation in worker failed: {}", job_id, exc)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—É—é –ª–æ–≥–∏–∫—É —á–µ—Ä–µ–∑ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        model_name = provider_options.get("model", "")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è Flux 2 Flex (–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–∞)
        if is_flux2flex:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            # –°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –ø–µ—Ä–µ–¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –Ω–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º—É –≤–∏–¥—É
            current_guidance = provider_options.get("guidance_scale", 5.0)
            if current_guidance > 7.0:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 7.0 –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–∞ (–±—ã–ª–æ 10.0 - —Å–ª–∏—à–∫–æ–º –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ)
                provider_options["guidance_scale"] = 7.0
                logger.info("Image job {}: Limited guidance_scale to 7.0 for Flux 2 Flex (was {}) to avoid over-detailing", job_id, current_guidance)
            elif current_guidance < 3.5:
                # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–∏–µ–º–ª–µ–º–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                provider_options["guidance_scale"] = 3.5
                logger.info("Image job {}: Set guidance_scale to 3.5 (min for Flux 2 Flex) for acceptable quality", job_id)
            
            # –¢–∞–∫–∂–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º num_inference_steps –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–∞
            current_steps = provider_options.get("num_inference_steps", 28)
            if current_steps > 35:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 35 –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–∞ (–±—ã–ª–æ 50 - —Å–ª–∏—à–∫–æ–º –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ)
                provider_options["num_inference_steps"] = 35
                logger.info("Image job {}: Limited num_inference_steps to 35 for Flux 2 Flex (was {}) to avoid over-detailing", job_id, current_steps)
            elif current_steps < 20:
                # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–∏–µ–º–ª–µ–º–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                provider_options["num_inference_steps"] = 20
                logger.info("Image job {}: Set num_inference_steps to 20 (min for Flux 2 Flex) for acceptable quality", job_id)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è nano-banana (–æ–±—ã—á–Ω—ã–π –∏ pro)
        is_nano_banana_regular = model_name == "fal-ai/nano-banana" or ("nano-banana" in model_name.lower() and "pro" not in model_name.lower())
        is_nano_banana_pro = "nano-banana-pro" in model_name.lower()
        
        if is_nano_banana_regular:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–æ–±—ã—á–Ω—ã–π nano-banana)
            current_steps = provider_options.get("num_inference_steps", 60)
            current_guidance = provider_options.get("guidance_scale", 9.0)
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º, –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–Ω—å—à–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö
            if current_steps < 60:
                provider_options["num_inference_steps"] = 60
            if current_guidance < 9.0:
                provider_options["guidance_scale"] = 9.0
            logger.info("Image job {}: Applied quality settings for nano-banana: num_inference_steps={}, guidance_scale={}", 
                       job_id, provider_options.get("num_inference_steps"), provider_options.get("guidance_scale"))
        elif is_nano_banana_pro:
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è nano-banana-pro (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Ä–∏—Å–æ–≤–∫–∞)
            provider_options["num_inference_steps"] = 90
            provider_options["guidance_scale"] = 10.0
            logger.info("Image job {}: Applied enhanced quality settings for nano-banana-pro: num_inference_steps={}, guidance_scale={}", 
                       job_id, provider_options.get("num_inference_steps"), provider_options.get("guidance_scale"))
        elif "seedream" in model_name.lower():
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è Seedream (—É–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –ø—Ä–æ—Ä–∏—Å–æ–≤–∫–∞ –∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è)
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            provider_options["num_inference_steps"] = 120
            provider_options["guidance_scale"] = 12.0
            # –î–æ–±–∞–≤–ª—è–µ–º enhance_prompt_mode –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (standard –≤–º–µ—Å—Ç–æ fast)
            provider_options["enhance_prompt_mode"] = "standard"
            logger.info("Image job {}: Applied enhanced quality settings for Seedream: num_inference_steps={}, guidance_scale={}, enhance_prompt_mode={}", 
                       job_id, provider_options.get("num_inference_steps"), provider_options.get("guidance_scale"), provider_options.get("enhance_prompt_mode"))
        
        logger.info("Image job {}: Submitting image job with model: {}", job_id, model_name)
        logger.info("Image job {}: provider_options keys: {}, width: {}, height: {}, num_inference_steps: {}, guidance_scale: {}", 
                   job_id, list(provider_options.keys()), provider_options.get("width"), provider_options.get("height"), 
                   provider_options.get("num_inference_steps"), provider_options.get("guidance_scale"))
        task_id = submit_image(prompt=provider_prompt, **provider_options)
        asset = None

        # Polling –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º 4 —Å–µ–∫)
        if asset is None:
            poll_attempts = 0
            max_attempts = 45  # 3 –º–∏–Ω—É—Ç—ã –ø—Ä–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ 4 —Å–µ–∫ (45 * 4 = 180 —Å–µ–∫—É–Ω–¥)
            poll_interval = 4.0  # –ò–Ω—Ç–µ—Ä–≤–∞–ª 4 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞
            status: dict[str, Any]
            logger.info("üì° POLLING START for job {} (task_id: {}): max_attempts={}, interval={}s", 
                       job_id, task_id[:8] if task_id else "None", max_attempts, poll_interval)
            while True:
                poll_attempts += 1
                logger.debug("üì° POLLING attempt {}/{} for job {} (task_id: {})", 
                           poll_attempts, max_attempts, job_id, task_id[:8] if task_id else "None")
                status = check_image_status(task_id)
                current_status = status.get("status")
                if current_status == "succeeded":
                    logger.info("üì° POLLING COMPLETE for job {}: succeeded after {} attempts ({} API requests)", 
                               job_id, poll_attempts, poll_attempts)
                    break
                if current_status == "failed":
                    error = status.get("error", "Unknown error")
                    logger.error("Image job {} failed: {}", job_id, error)
                    if job:
                        job.meta["error"] = error
                        job.save_meta()
                    if notify_options.get("chat_id"):
                        _send_failure_notification_sync(notify_options, job_id, str(error))
                    raise RuntimeError(error)
                if poll_attempts >= max_attempts:
                    error = f"fal request did not complete within {int(max_attempts * poll_interval)} seconds"
                    logger.error("üì° POLLING TIMEOUT for job {}: {} attempts ({} API requests)", 
                               job_id, poll_attempts, poll_attempts)
                    if job:
                        job.meta["error"] = error
                        job.save_meta()
                    if notify_options.get("chat_id"):
                        _send_failure_notification_sync(notify_options, job_id, error)
                    raise RuntimeError(error)
                if poll_attempts % 5 == 0:  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 5 –ø–æ–ø—ã—Ç–æ–∫
                    logger.info("üì° POLLING progress for job {}: attempt {}/{}, status={}", 
                               job_id, poll_attempts, max_attempts, current_status)
                time.sleep(poll_interval)

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        if asset is None:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä—è–º–æ –≤ —Å—Ç–∞—Ç—É—Å–µ (–∫–∞–∫ –¥–ª—è Seedream –≤ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏)
            from app.providers.fal.images import _extract_image_url as extract_image_url
            status_image_url = extract_image_url(status)

            if status_image_url:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç URL
                if status_image_url.startswith("data:"):
                    logger.info("Image job {} result found in status response (data URL)", job_id)
                    from app.providers.fal.images import ImageAsset
                    import base64
                    header, _, data_part = status_image_url.partition(",")
                    content = base64.b64decode(data_part)
                    asset = ImageAsset(url=None, content=content, filename="image.png")
                elif status_image_url.startswith("http") and not (status_image_url.startswith("https://queue.fal.run") or status_image_url.startswith("http://queue.fal.run")):
                    logger.info("Image job {} result found in status response (direct URL): {}", job_id, status_image_url[:100])
                    from app.providers.fal.images import ImageAsset
                    asset = ImageAsset(url=status_image_url, content=None, filename=None)
                elif status_image_url.startswith("https://queue.fal.run") or status_image_url.startswith("http://queue.fal.run"):
                    # –≠—Ç–æ endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –Ω–µ –ø—Ä—è–º–æ–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ–±—ã—á–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    logger.debug("Image job {} status contains queue endpoint, will resolve through resolve_image_asset", job_id)
                    status_image_url = None

            # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –≤ —Å—Ç–∞—Ç—É—Å–µ, –ø–æ–ª—É—á–∞–µ–º —á–µ—Ä–µ–∑ response_url
            if asset is None:
                result_url = status.get("result_url")
                if not result_url:
                    error = "–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
                    logger.error("Image job {} task {} completed without result URL or result in status", job_id, task_id)
                    if job:
                        job.meta["error"] = error
                        job.save_meta()
                    if notify_options.get("chat_id"):
                        _send_failure_notification_sync(notify_options, job_id, error)
                    raise RuntimeError(error)

                # –î–ª—è nano-banana-pro –∏—Å–ø–æ–ª—å–∑—É–µ–º URL –Ω–∞–ø—Ä—è–º—É—é, –±–µ–∑ resolve_image_asset
                # —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–æ–ª–≥–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
                is_nano_banana_pro = model_name == "fal-ai/nano-banana-pro" or "nano-banana-pro" in model_name.lower()
                
                if is_nano_banana_pro:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ result_url - —ç—Ç–æ –ø—Ä—è–º–æ–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞ –Ω–µ API endpoint
                    # API endpoints –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç "/requests/" –∏–ª–∏ "/response" –∏–ª–∏ "/result"
                    is_api_endpoint = (
                        "/requests/" in result_url or 
                        "/response" in result_url or 
                        "/result" in result_url or
                        "queue.fal.run" in result_url
                    )
                    
                    if is_api_endpoint:
                        # –ï—Å–ª–∏ —ç—Ç–æ API endpoint, –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ø—Ä—è–º–æ–π URL —á–µ—Ä–µ–∑ resolve_image_asset
                        logger.warning("Image job {}: Nano Banana Pro result_url is API endpoint, will use resolve_image_asset to get direct URL: {}", 
                                     job_id, result_url[:100])
                        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                        time.sleep(0.5)
                        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä—è–º–æ–π URL —á–µ—Ä–µ–∑ resolve_image_asset (–Ω–æ –Ω–µ —Å–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª)
                        try:
                            asset = resolve_image_asset(result_url)
                            logger.info("Image job {}: Got direct image URL from resolve_image_asset: {}", 
                                       job_id, asset.url[:100] if asset.url else "None")
                        except Exception as exc:
                            logger.error("Image job {}: Failed to get direct URL from resolve_image_asset: {}", job_id, exc)
                            raise
                    else:
                        # –≠—Ç–æ –ø—Ä—è–º–æ–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é
                        logger.info("Image job {}: Nano Banana Pro detected, using result_url directly (direct image URL): {}", 
                                   job_id, result_url[:100])
                        from app.providers.fal.images import ImageAsset
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º result_url –∫–∞–∫ –ø—Ä—è–º–æ–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (Telegram —Å–∞–º —Å–∫–∞—á–∞–µ—Ç)
                        asset = ImageAsset(url=result_url, content=None, filename=None)
                else:
                    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, —á—Ç–æ–±—ã API —É—Å–ø–µ–ª –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    time.sleep(0.5)

                    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ (–∫–∞–∫ –¥–ª—è Nano-banana)
                    max_result_attempts = 3
                    result_delay = 0.5
                    last_result_error: Exception | None = None

                    for result_attempt in range(max_result_attempts):
                        try:
                            asset = resolve_image_asset(result_url)
                            logger.info("Image job {} successfully got result on attempt {}: asset.url={}, asset.content={}", 
                                       job_id, result_attempt + 1, asset.url[:100] if asset.url else "None", asset.content is not None)
                            break
                        except httpx.HTTPStatusError as exc:
                            last_result_error = exc
                            status_code = exc.response.status_code
                            if status_code in (500, 502, 503, 401) and result_attempt < max_result_attempts - 1:
                                logger.warning(
                                    "Image job {} result attempt {} failed with {}: {}. Retrying in {:.1f}s",
                                    job_id,
                                    result_attempt + 1,
                                    status_code,
                                    exc.response.text[:100] if hasattr(exc.response, 'text') else str(exc),
                                    result_delay,
                                )
                                time.sleep(result_delay)
                                result_delay *= 1.5
                                continue
                            else:
                                logger.error("Image job {} result attempt {} failed with {}: {}", job_id, result_attempt + 1, status_code, exc)
                                raise
                        except Exception as exc:  # noqa: BLE001
                            last_result_error = exc
                            logger.error("Image job {} result attempt {} failed: {}", job_id, result_attempt + 1, exc)
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–æ–π content policy violation
                            error_str = str(exc)
                            if "content policy violation" in error_str.lower() or "content checker" in error_str.lower():
                                # –≠—Ç–æ –æ—à–∏–±–∫–∞ –ø–æ–ª–∏—Ç–∏–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                                user_error_msg = (
                                    "‚ùå –ó–∞–ø—Ä–æ—Å –æ—Ç–∫–ª–æ–Ω–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\n\n"
                                    "–í–∞—à –ø—Ä–æ–º–ø—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏–∑-–∑–∞ –ø–æ–ª–∏—Ç–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\n\n"
                                    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç, —É–±—Ä–∞–≤ –∏–ª–∏ –∏–∑–º–µ–Ω–∏–≤ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã."
                                )
                                logger.warning("Image job {} rejected by content policy", job_id)
                                if job:
                                    job.meta["error"] = "Content policy violation"
                                    job.save_meta()
                                if notify_options.get("chat_id"):
                                    _send_failure_notification_sync(notify_options, job_id, user_error_msg)
                                raise RuntimeError("Content policy violation") from exc
                            if result_attempt >= max_result_attempts - 1:
                                raise

                    if asset is None:
                        error = last_result_error or RuntimeError("Failed to get image result")
                        error_str = str(error)
                        logger.error("Image job {} failed to get result after {} attempts: {}", job_id, max_result_attempts, error)
                        
                        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏
                        if "content policy violation" in error_str.lower() or "content checker" in error_str.lower():
                            user_error_msg = (
                                "‚ùå –ó–∞–ø—Ä–æ—Å –æ—Ç–∫–ª–æ–Ω–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\n\n"
                                "–í–∞—à –ø—Ä–æ–º–ø—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏–∑-–∑–∞ –ø–æ–ª–∏—Ç–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\n\n"
                                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç, —É–±—Ä–∞–≤ –∏–ª–∏ –∏–∑–º–µ–Ω–∏–≤ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã."
                            )
                        elif "fal response did not include an image url" in error_str.lower():
                            user_error_msg = (
                                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n\n"
                                "–°–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                                "‚Ä¢ –ó–∞–ø—Ä–æ—Å –±—ã–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏\n"
                                "‚Ä¢ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ä–≤–∏—Å–æ–º\n\n"
                                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–∑–∂–µ."
                            )
                        else:
                            user_error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {error}"
                        
                        if job:
                            job.meta["error"] = str(error)
                            job.save_meta()
                        if notify_options.get("chat_id"):
                            _send_failure_notification_sync(notify_options, job_id, user_error_msg)
                        raise RuntimeError(str(error))

        image_url = asset.url
        image_bytes = asset.content
        filename = asset.filename
        saved_path = None

        # –î–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ, –∫—Ä–æ–º–µ —Å–ª—É—á–∞–µ–≤ –∫–æ–≥–¥–∞:
        # 1. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ –≤ –ø–∞–º—è—Ç–∏ (image_bytes) - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (–±—ã—Å—Ç—Ä–æ, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç)
        
        # –ú–æ–¥–µ–ª–∏ –ø–æ–ª—É—á–∞—é—Ç aspect_ratio –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∑–∞–ø—Ä–æ—Å–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ–º —Å—Ç–æ—Ä–æ–Ω
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        
        if image_bytes is not None:
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ –≤ –ø–∞–º—è—Ç–∏ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (–±—ã—Å—Ç—Ä–æ)
            file_size_kb = len(image_bytes) / 1024
            logger.info("üíæ Image job {}: saving from memory ({} bytes, {:.2f} KB) - no download needed", 
                       job_id, len(image_bytes), file_size_kb)
            saved_path = _persist_asset(asset, output_file.as_posix())
            if saved_path and saved_path.exists():
                saved_size_kb = saved_path.stat().st_size / 1024
                logger.info("‚úÖ Image job {}: saved to disk - {:.2f} KB ({} bytes)", 
                           job_id, saved_size_kb, saved_path.stat().st_size)
        elif image_url:
            # –î–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ URL —Å—Ä–∞–∑—É, —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–¥–µ—Ç –≤ —Ñ–æ–Ω–µ
            logger.info("üîÑ Image job {}: ASYNC MODE - sending by URL immediately, download in background", job_id)
            saved_path = None
            # –ü–ª–∞–Ω–∏—Ä—É–µ–º —Ñ–æ–Ω–æ–≤–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
            _schedule_result_download(job_id, image_url, output_file)
        else:
            saved_path = None

        if job:
            if image_url:
                job.meta["image_url"] = image_url
            if image_bytes:
                job.meta["image_inline"] = True
                if filename:
                    job.meta["image_filename"] = filename
            if saved_path:
                job.meta["result_path"] = saved_path.as_posix()
            elif image_url:
                job.meta["result_path"] = None
            job.save_meta()

        # –§–æ–Ω–æ–≤–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ –≤—ã—à–µ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π (–∫—Ä–æ–º–µ —Å–ª—É—á–∞–µ–≤ —Å image_bytes)

        logger.success("Image job {} completed: {}", job_id, image_url or filename or "binary")
        if notify_options.get("chat_id"):
            try:
                reply_markup = None
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º saved_path –∏–∑ job.meta –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ —Ñ–æ–Ω–æ–≤–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å
                if saved_path is None and job and job.meta.get("result_path"):
                    saved_path = Path(job.meta["result_path"])
                    if not saved_path.exists():
                        saved_path = None
                
                if image_bytes is not None:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_bytes=image_bytes,
                        filename=filename,
                        reply_markup=reply_markup,
                    )
                elif saved_path and saved_path.exists():
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–º–µ—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    logger.info("Using already downloaded file for notification: {} (size: {:.2f} KB)", 
                               saved_path, saved_path.stat().st_size / 1024)
                    with open(saved_path, "rb") as f:
                        image_bytes = f.read()
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_bytes=image_bytes,
                        filename=filename or saved_path.name,
                        reply_markup=reply_markup,
                    )
                else:
                    # –î–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ URL –Ω–∞–ø—Ä—è–º—É—é
                    # –≠—Ç–æ –∏–∑–±–µ–≥–∞–µ—Ç –¥–≤–æ–π–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è)
                    # Telegram —Å–∫–∞—á–∞–µ—Ç —Ñ–∞–π–ª —Å–∞–º, –∞ –º—ã –∫–µ—à–∏—Ä—É–µ–º –µ–≥–æ –≤ —Ñ–æ–Ω–µ
                    logger.info("üì§ Sending by URL directly (async download in background, no duplicate download): {}", image_url[:100] if image_url else "None")
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_url=image_url,
                        reply_markup=reply_markup,
                    )
            except Exception as notify_error:  # noqa: BLE001
                logger.error("Failed to send Telegram notification for job {}: {}", job_id, notify_error, exc_info=True)

        # Confirm operation after successful completion
        if operation_id:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º DATABASE_URL –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (PostgreSQL –∏–ª–∏ SQLite)
            db = SessionLocal()
            try:
                logger.info("Confirming operation {} for job {}: using DATABASE_URL from settings", operation_id, job_id)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –æ–ø–µ—Ä–∞—Ü–∏—è –ø–µ—Ä–µ–¥ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º
                from app.db.models import Operation
                operation_check = db.query(Operation).filter(Operation.id == operation_id).first()
                if operation_check:
                    logger.info("Operation {} found: status={}, type={}, user_id={}", 
                               operation_id, operation_check.status, operation_check.type, operation_check.user_id)
                else:
                    logger.warning("Operation {} not found in database, will try to confirm anyway", operation_id)
                
                success = BillingService.confirm_operation(db, operation_id)
                if success:
                    logger.info("Confirmed operation {} for job {}", operation_id, job_id)
                else:
                    logger.error("Failed to confirm operation {} for job {}", operation_id, job_id)
            except Exception as e:
                logger.error("Error confirming operation {} for job {}: {}", operation_id, job_id, e, exc_info=True)
            finally:
                db.close()

        return image_url or ""
    except JobTimeoutException as timeout_exc:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –∑–∞–¥–∞—á–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        logger.error("Image job {} timed out after 4 minutes", job_id)
        _handle_job_timeout(job_id, notify_options, "–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        # Mark operation as failed
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for job {} due to timeout", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise
    except Exception as e:
        error_str = str(e)
        error_type = type(e).__name__
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏
        user_error_msg = None
        
        if "content policy violation" in error_str.lower() or "content checker" in error_str.lower():
            user_error_msg = (
                "‚ùå –ó–∞–ø—Ä–æ—Å –æ—Ç–∫–ª–æ–Ω–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\n\n"
                "–í–∞—à –ø—Ä–æ–º–ø—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏–∑-–∑–∞ –ø–æ–ª–∏—Ç–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç, —É–±—Ä–∞–≤ –∏–ª–∏ –∏–∑–º–µ–Ω–∏–≤ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã."
            )
        elif "fal response did not include an image url" in error_str.lower():
            user_error_msg = (
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n\n"
                "–°–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                "‚Ä¢ –ó–∞–ø—Ä–æ—Å –±—ã–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏\n"
                "‚Ä¢ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ä–≤–∏—Å–æ–º\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–∑–∂–µ."
            )
        elif isinstance(e, httpx.HTTPStatusError):
            status_code = e.response.status_code if hasattr(e, 'response') else None
            if status_code == 422:
                user_error_msg = (
                    "‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞.\n\n"
                    "–ó–∞–ø—Ä–æ—Å –±—ã–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω —Å–µ—Ä–≤–∏—Å–æ–º. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                    "‚Ä¢ –ü—Ä–æ–º–ø—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç, –Ω–∞—Ä—É—à–∞—é—â–∏–π –ø–æ–ª–∏—Ç–∏–∫—É –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏\n"
                    "‚Ä¢ –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n\n"
                    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã."
                )
            elif status_code == 429:
                user_error_msg = (
                    "‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤.\n\n"
                    "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ —Å–µ—Ä–≤–∏—Å—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
                )
            elif status_code in (500, 502, 503):
                user_error_msg = (
                    "‚ùå –í—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å —Å–µ—Ä–≤–∏—Å–æ–º.\n\n"
                    "–°–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
                )
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ
        if user_error_msg and notify_options and notify_options.get("chat_id"):
            try:
                _send_failure_notification_sync(notify_options, job_id, user_error_msg)
            except Exception as notify_exc:
                logger.error("Failed to send error notification for job {}: {}", job_id, notify_exc)
        
        # Mark operation as failed on any error
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for job {} due to error: {}", operation_id, job_id, error_type)
            except Exception as fail_error:
                logger.error("Error failing operation {} for job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise


def process_image_edit_job(
    job_id: str,
    prompt: str,
    image_path: str,
    mask_path: str | None,
    options: dict | None,
    output_path: str,
) -> str:
    # Import models to ensure they are registered with Base.metadata
    from app.db import models  # noqa: F401
    from app.services.billing import BillingService
    from app.db.base import SessionLocal

    provider_options: Dict[str, Any] = dict(options or {})
    operation_id_raw = provider_options.pop("operation_id", None)
    operation_id = _parse_operation_id(operation_id_raw, job_id, "Image edit")
    logger.info("Image edit job {}: operation_id_raw={} (type: {}), parsed operation_id={}", 
               job_id, operation_id_raw, type(operation_id_raw).__name__ if operation_id_raw is not None else "None", operation_id)
    provider_prompt = provider_options.pop("provider_prompt", prompt)
    model_name = provider_options.setdefault("model", settings.fal_edit_model)
    requires_mask = model_requires_mask(model_name)
    
    # –î–ª—è Seedream edit —É–±–∏—Ä–∞–µ–º enhance_prompt_mode, —á—Ç–æ–±—ã –ø—Ä–æ–º–ø—Ç –ø–µ—Ä–µ–¥–∞–≤–∞–ª—Å—è –∫–∞–∫ –µ—Å—Ç—å –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–π
    # –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if "seedream" in model_name.lower() and "/edit" in model_name.lower():
        if "enhance_prompt_mode" in provider_options:
            logger.info("Edit job {}: Removing enhance_prompt_mode for Seedream edit to improve prompt understanding", job_id)
            provider_options.pop("enhance_prompt_mode", None)

    notify_options = _extract_notify_options(provider_options)
    output_file = Path(output_path)
    source_file = Path(image_path)
    mask_file = Path(mask_path) if mask_path else None

    job = get_current_job()

    try:
        if job:
            job.meta.update(
                {
                    "prompt": prompt,
                    "edit": True,
                    "source_path": source_file.as_posix(),
                }
            )
            if mask_file:
                job.meta["mask_path"] = mask_file.as_posix()
            if prompt != provider_prompt:
                job.meta["provider_prompt"] = provider_prompt
            job.save_meta()

        logger.info(
            "Processing image edit job {} with prompt {} (source={}, mask={})",
            job_id,
            prompt,
            image_path,
            mask_path,
        )

        if not source_file.exists():
            error = f"Source image for job {job_id} not found at {image_path}"
            logger.error(error)
            if job:
                job.meta["error"] = error
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, error)
            raise RuntimeError(error)

        if requires_mask:
            if mask_file is None or not mask_file.exists():
                error = "–î–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –Ω—É–∂–Ω–∞ –º–∞—Å–∫–∞, –≤—ã–¥–µ–ª—è—é—â–∞—è –æ–±–ª–∞—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è."
                logger.error("Edit job {} missing mask file", job_id)
                if job:
                    job.meta["error"] = error
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, error)
                raise RuntimeError(error)
        else:
            if mask_file is None or not mask_file.exists():
                mask_file = None

        # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º —Å polling –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        # –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ Face swap –∏ Retoucher
        logger.info("Using asynchronous queue mode for edit model {} in edit job {}", model_name, job_id)
        try:
            task_id = submit_image_edit(
                image_path=source_file.as_posix(),
                prompt=provider_prompt,
                mask_path=mask_file.as_posix() if mask_file else None,
                **provider_options,
            )
        except Exception as exc:  # noqa: BLE001
            logger.error("Failed to submit edit job {} to fal: {}", job_id, exc)
            if job:
                job.meta["error"] = str(exc)
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, str(exc))
            raise

        # Polling –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º backoff
        poll_attempts = 0
        max_attempts = 120  # allow up to ~4 minutes for edit jobs (with backoff)
        poll_interval = 2.0  # Start with 2 seconds
        min_interval = 2.0
        max_interval = 10.0

        logger.info("Edit job {} polling for task {} completion", job_id, task_id)
        while True:
            status = check_image_status(task_id)
            current_status = status.get("status")
            # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å —Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–µ 5 –ø–æ–ø—ã—Ç–æ–∫ –∏–ª–∏ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞
            if poll_attempts % 5 == 0 or current_status not in ("processing", "queued"):
                logger.debug("Edit job {} task {} status: {} (attempt {})", job_id, task_id, current_status, poll_attempts + 1)

            if current_status == "succeeded":
                break
            if current_status == "failed":
                error = status.get("error", "Unknown error")
                logger.error("Edit job {} task {} failed: {}", job_id, task_id, error)
                if job:
                    job.meta["error"] = error
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, f"–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {error}")
                raise RuntimeError(error)

            poll_attempts += 1
            if poll_attempts >= max_attempts:
                error = f"–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–≤—ã—Å–∏–ª–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è"
                logger.error("Edit job {} task {} timed out after {} attempts", job_id, task_id, poll_attempts)
                if job:
                    job.meta["error"] = error
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, "–ó–∞–¥–∞—á–∞ –ø—Ä–µ–≤—ã—Å–∏–ª–∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                raise RuntimeError(error)

            # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π backoff: —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–æ –º–∞–∫—Å–∏–º—É–º–∞
            time.sleep(poll_interval)
            poll_interval = min(poll_interval * 1.1, max_interval)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –Ω–∞ 10% –¥–æ –º–∞–∫—Å–∏–º—É–º–∞

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä—è–º–æ –≤ —Å—Ç–∞—Ç—É—Å–µ
        from app.providers.fal.images import _extract_image_url as extract_image_url
        status_image_url = extract_image_url(status)
        asset = None

        if status_image_url:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç URL
            if status_image_url.startswith("data:"):
                logger.info("Edit job {} result found in status response (data URL)", job_id)
                from app.providers.fal.images import ImageAsset
                import base64
                header, _, data_part = status_image_url.partition(",")
                content = base64.b64decode(data_part)
                asset = ImageAsset(url=None, content=content, filename="edit.png")
            elif status_image_url.startswith("http") and not (status_image_url.startswith("https://queue.fal.run") or status_image_url.startswith("http://queue.fal.run")):
                logger.info("Edit job {} result found in status response (direct URL): {}", job_id, status_image_url[:100])
                from app.providers.fal.images import ImageAsset
                asset = ImageAsset(url=status_image_url, content=None, filename=None)

        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –≤ —Å—Ç–∞—Ç—É—Å–µ, –ø–æ–ª—É—á–∞–µ–º —á–µ—Ä–µ–∑ result_url –∏–ª–∏ response_url
        if asset is None:
            # –î–ª—è nano-banana/edit –∏—Å–ø–æ–ª—å–∑—É–µ–º response_url, –µ—Å–ª–∏ result_url –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            result_url = status.get("result_url") or status.get("response_url")
            if not result_url:
                error = "–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
                logger.error("Edit job {} task {} completed without result URL or result in status", job_id, task_id)
                if job:
                    job.meta["error"] = error
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, error)
                raise RuntimeError(error)

            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, —á—Ç–æ–±—ã API —É—Å–ø–µ–ª –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 1s –¥–æ 0.5s –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            time.sleep(0.5)

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
            max_result_attempts = 3  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 5 –¥–æ 3 –ø–æ–ø—ã—Ç–æ–∫
            result_delay = 0.5  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 1.0 –¥–æ 0.5 —Å–µ–∫—É–Ω–¥—ã
            last_result_error: Exception | None = None

            for result_attempt in range(max_result_attempts):
                try:
                    asset = resolve_image_asset(result_url)
                    logger.info("Edit job {} successfully got result on attempt {}: asset.url={}, asset.content={}", 
                               job_id, result_attempt + 1, asset.url[:100] if asset.url else "None", asset.content is not None)
                    break
                except httpx.HTTPStatusError as exc:
                    last_result_error = exc
                    status_code = exc.response.status_code
                    if status_code in (500, 502, 503, 401) and result_attempt < max_result_attempts - 1:
                        logger.warning(
                            "Edit job {} result attempt {} failed with {}: {}. Retrying in {:.1f}s",
                            job_id,
                            result_attempt + 1,
                            status_code,
                            exc.response.text[:100] if hasattr(exc.response, 'text') else str(exc),
                            result_delay,
                        )
                        time.sleep(result_delay)
                        result_delay *= 1.5
                        continue
                    else:
                        logger.error("Edit job {} result attempt {} failed with {}: {}", job_id, result_attempt + 1, status_code, exc)
                        raise
                except Exception as exc:  # noqa: BLE001
                    last_result_error = exc
                    logger.error("Edit job {} result attempt {} failed: {}", job_id, result_attempt + 1, exc)
                    if result_attempt >= max_result_attempts - 1:
                        raise

            if asset is None:
                error = last_result_error or RuntimeError("Failed to get edit result")
                logger.error("Edit job {} failed to get result after {} attempts: {}", job_id, max_result_attempts, error)
                if job:
                    job.meta["error"] = str(error)
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {error}")
                raise RuntimeError(str(error))

        image_url = asset.url
        image_bytes = asset.content
        filename = asset.filename
        saved_path = None
        if image_bytes is not None:
            saved_path = _persist_asset(asset, output_file.as_posix())

        if job:
            if image_url:
                job.meta["image_url"] = image_url
            if image_bytes:
                job.meta["image_inline"] = True
                if filename:
                    job.meta["image_filename"] = filename
            if saved_path:
                job.meta["result_path"] = saved_path.as_posix()
            elif image_url:
                job.meta["result_path"] = None
            job.save_meta()

        if saved_path is None and image_url:
            _schedule_result_download(job_id, image_url, output_file)

        logger.success("Edit job {} completed: {}", job_id, image_url or filename or "binary")
        if notify_options.get("chat_id"):
            try:
                reply_markup = None
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫: Stylish text —Ç–æ–ª—å–∫–æ –¥–ª—è –º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –ò–°–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–û –≤ Stylish text —Ä–µ–∂–∏–º–µ
                # Seedream –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏ –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –ø–æ—ç—Ç–æ–º—É –Ω–µ –≤–∫–ª—é—á–∞–µ–º –µ—ë –≤ —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫
                stylish_models = {"fal-ai/ideogram/v2/edit", "fal-ai/reve/fast/edit", "fal-ai/gpt-image-1-mini/edit"}
                is_stylish = model_name in stylish_models
                logger.info("Edit job {}: model_name='{}', is_stylish={}, stylish_models={}", 
                            job_id, model_name, is_stylish, stylish_models)
                caption_title = "‚ú® Stylish text –≥–æ—Ç–æ–≤!" if is_stylish else "üõ†Ô∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!"
                logger.info("Edit job {}: caption_title='{}'", job_id, caption_title)
                if image_bytes is not None:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_bytes=image_bytes,
                        filename=filename,
                        caption_title=caption_title,
                        reply_markup=reply_markup,
                    )
                else:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_url=image_url,
                        caption_title=caption_title,
                        reply_markup=reply_markup,
                    )
            except Exception as notify_error:  # noqa: BLE001
                logger.error("Failed to send Telegram notification for edit job {}: {}", job_id, notify_error)

        # Confirm operation after successful completion
        if operation_id:
            logger.info("Image edit job {}: attempting to confirm operation_id={} (type: {})", 
                       job_id, operation_id, type(operation_id).__name__)
            db = SessionLocal()
            try:
                success = BillingService.confirm_operation(db, operation_id)
                if success:
                    logger.info("Confirmed operation {} for edit job {}", operation_id, job_id)
                else:
                    logger.error("Failed to confirm operation {} for edit job {} - operation may not exist or already processed", 
                               operation_id, job_id)
            except Exception as e:
                logger.error("Error confirming operation {} for edit job {}: {}", operation_id, job_id, e, exc_info=True)
            finally:
                db.close()
        else:
            logger.warning("Image edit job {}: no operation_id provided, skipping billing confirmation", job_id)

        return image_url or ""
    except JobTimeoutException as timeout_exc:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –∑–∞–¥–∞—á–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        logger.error("Image edit job {} timed out after 4 minutes", job_id)
        _handle_job_timeout(job_id, notify_options, "—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        # Mark operation as failed
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for edit job {} due to timeout", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for edit job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise
    except Exception as e:
        # Mark operation as failed on any error
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for edit job {} due to error", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for edit job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise


def process_retoucher_job(
    job_id: str,
    prompt: str,
    image_path: str,
    mode: str,
    instruction: str | None,
    options: dict | None,
    output_path: str,
) -> str:
    logger.info("process_retoucher_job called: job_id={}, mode={}, model={}", 
                job_id, mode, RETOUCHER_MODELS.get(mode, "default"))
    # Import models to ensure they are registered with Base.metadata
    from app.db import models  # noqa: F401
    from app.services.billing import BillingService
    from app.db.base import SessionLocal

    provider_options: Dict[str, Any] = dict(options or {})
    operation_id_raw = provider_options.pop("operation_id", None)
    operation_id = _parse_operation_id(operation_id_raw, job_id, "Retoucher")
    provider_prompt = provider_options.pop("provider_prompt", prompt)
    model_name = provider_options.setdefault("model", RETOUCHER_MODELS.get(mode, settings.fal_retoucher_model))
    logger.info("process_retoucher_job: model_name={}, prompt={}", model_name, prompt[:100] if prompt else "None")

    notify_options = _extract_notify_options(provider_options)
    output_file = Path(output_path)
    source_file = Path(image_path)

    job = get_current_job()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º asset = None, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å UnboundLocalError
    asset = None

    try:
        if job:
            job.meta.update(
                {
                    "prompt": prompt,
                    "retoucher": True,
                    "mode": mode,
                    "instruction": instruction,
                    "source_path": source_file.as_posix(),
                }
            )
            if prompt != provider_prompt:
                job.meta["provider_prompt"] = provider_prompt
            job.save_meta()

        logger.info(
            "Processing retoucher job {} mode={} instruction={}",
            job_id,
            mode,
            instruction,
        )

        if not source_file.exists():
            error = "–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
            logger.error("Retoucher job {} missing source {}", job_id, image_path)
            if job:
                job.meta["error"] = error
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, error)
            raise RuntimeError(error)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
        try:
            file_size = source_file.stat().st_size
        except Exception as stat_exc:
            error = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ: {stat_exc}"
            logger.error("Retoucher job {} failed to stat source file: {}", job_id, stat_exc)
            if job:
                job.meta["error"] = error
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, error)
            raise RuntimeError(error)
        if file_size > RETOUCHER_MAX_FILE_BYTES:
            file_size_mb = file_size / (1024 * 1024)
            error = (
                f"‚ùå –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size_mb:.1f} –ú–ë).\n\n"
                f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–º –º–µ–Ω–µ–µ 10 –ú–ë."
            )
            logger.error(
                "Retoucher job {}: source image size {:.2f}MB exceeds limit {:.2f}MB",
                job_id,
                file_size_mb,
                RETOUCHER_MAX_FILE_BYTES / (1024 * 1024),
            )
            if job:
                job.meta["error"] = error
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, error)
            raise RuntimeError(error)

        # –î–ª—è Nano Banana edit –≤ —Ä–µ–∂–∏–º–µ "enhance" –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º
        is_nano_banana_edit_enhance = (
            mode == "enhance" and 
            "nano-banana" in model_name.lower() and 
            "/edit" in model_name.lower() and 
            "pro" not in model_name.lower()
        )
        
        if is_nano_banana_edit_enhance:
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è Nano Banana edit (–æ–±—ã—á–Ω—ã–π)
            provider_options.setdefault("num_inference_steps", 90)
            provider_options.setdefault("guidance_scale", 9.0)
            logger.info("Retoucher job {}: Using synchronous mode for Nano Banana edit with quality settings: num_inference_steps={}, guidance_scale={}", 
                       job_id, provider_options.get("num_inference_steps"), provider_options.get("guidance_scale"))
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è nano-banana/edit
            from app.providers.fal.images import run_image_edit
            try:
                asset = run_image_edit(
                    image_path=source_file.as_posix(),
                    prompt=provider_prompt,
                    mask_path=None,
                    **provider_options,
                )
                logger.info("Retoucher job {}: Got result from synchronous run_image_edit: asset.url={}, asset.content={}", 
                           job_id, asset.url[:100] if asset.url else "None", asset.content is not None)
            except Exception as exc:  # noqa: BLE001
                logger.error("Retoucher job {} synchronous run_image_edit failed: {}", job_id, exc)
                if job:
                    job.meta["error"] = str(exc)
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, f"–û—à–∏–±–∫–∞ —Ä–µ—Ç—É—à–∏: {exc}")
                raise
        else:
            # –î–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π queue API
            task_id: str | None = None
            last_error: Exception | None = None
            for attempt in range(1, RETOUCHER_SUBMIT_MAX_ATTEMPTS + 1):
                try:
                    from app.providers.fal.images import submit_image_edit
                    task_id = submit_image_edit(
                        image_path=source_file.as_posix(),
                        prompt=provider_prompt,
                        mask_path=None,
                        **provider_options,
                    )
                    break
                except httpx.RequestError as exc:
                    last_error = exc
                    logger.warning(
                        "Retoucher job {} submit attempt {} failed: {}",
                        job_id,
                        attempt,
                        exc,
                    )
                    if attempt < RETOUCHER_SUBMIT_MAX_ATTEMPTS:
                        time.sleep(RETOUCHER_SUBMIT_BACKOFF * attempt)
                except Exception as exc:  # noqa: BLE001
                    last_error = exc
                    logger.error("Retoucher job {} submit failed: {}", job_id, exc)
                    break

            if task_id is None:
                error_text = "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä–µ—Ç—É—à—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
                if job:
                    job.meta["error"] = str(last_error) if last_error else error_text
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, error_text)
                if last_error:
                    raise last_error
                raise RuntimeError(error_text)

            # –î–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π polling
            from app.providers.fal.images import check_status as check_image_status
            from app.providers.fal.images import resolve_result_asset as resolve_image_asset
            
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π polling –¥–ª—è –º—è–≥–∫–æ–π —Ä–µ—Ç—É—à–∏ - –∫–∞–∫ —É Nano Banana (4 —Å–µ–∫—É–Ω–¥—ã)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª, —á—Ç–æ –∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            poll_attempts = 0
            max_attempts = 45  # 3 –º–∏–Ω—É—Ç—ã –ø—Ä–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ 4 —Å–µ–∫ (45 * 4 = 180 —Å–µ–∫—É–Ω–¥)
            poll_interval = 4.0  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª 4 —Å–µ–∫—É–Ω–¥—ã (–∫–∞–∫ —É Nano Banana)
            status: dict[str, Any]
            
            logger.info("Retoucher job {} polling for task {} completion (interval: {}s, max_attempts: {})", 
                       job_id, task_id, poll_interval, max_attempts)
            while True:
                status = check_image_status(task_id)
                current_status = status.get("status")
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å —Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–µ 5 –ø–æ–ø—ã—Ç–æ–∫ –∏–ª–∏ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞
                if poll_attempts % 5 == 0 or current_status not in ("processing", "queued", "IN_QUEUE", "IN_PROGRESS"):
                    logger.debug("Retoucher job {} task {} status: {} (attempt {})", 
                               job_id, task_id, current_status, poll_attempts + 1)

                if current_status == "succeeded":
                    logger.info("Retoucher job {} succeeded after {} attempts", job_id, poll_attempts + 1)
                    break
                if current_status == "failed":
                    error = status.get("error", "Unknown error")
                    logger.error("Retoucher job {} failed: {}", job_id, error)
                    if job:
                        job.meta["error"] = error
                        job.save_meta()
                    if notify_options.get("chat_id"):
                        _send_failure_notification_sync(notify_options, job_id, str(error))
                    raise RuntimeError(error)
                poll_attempts += 1
                if poll_attempts >= max_attempts:
                    error = "–í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è —Ä–µ—Ç—É—à–∏ –∏—Å—Ç–µ–∫–ª–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
                    logger.error("Retoucher job {} timed out after {} attempts", job_id, poll_attempts)
                    if job:
                        job.meta["error"] = error
                        job.save_meta()
                    if notify_options.get("chat_id"):
                        _send_failure_notification_sync(notify_options, job_id, error)
                    raise RuntimeError(error)

                # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª 4 —Å–µ–∫—É–Ω–¥—ã (–∫–∞–∫ —É Nano Banana)
                time.sleep(poll_interval)

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            from app.providers.fal.images import _extract_image_url as extract_image_url
            status_image_url = extract_image_url(status)
            asset = None

            if status_image_url:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç URL
                if status_image_url.startswith("data:"):
                    logger.info("Retoucher job {} result found in status response (data URL)", job_id)
                    from app.providers.fal.images import ImageAsset
                    import base64
                    header, _, data_part = status_image_url.partition(",")
                    content = base64.b64decode(data_part)
                    asset = ImageAsset(url=None, content=content, filename="retouch.png")
                elif status_image_url.startswith("http") and not (status_image_url.startswith("https://queue.fal.run") or status_image_url.startswith("http://queue.fal.run")):
                    logger.info("Retoucher job {} result found in status response (direct URL): {}", job_id, status_image_url[:100])
                    from app.providers.fal.images import ImageAsset
                    asset = ImageAsset(url=status_image_url, content=None, filename=None)

            # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –≤ —Å—Ç–∞—Ç—É—Å–µ, –ø–æ–ª—É—á–∞–µ–º —á–µ—Ä–µ–∑ result_url –∏–ª–∏ response_url
            if asset is None:
                result_url = status.get("result_url") or status.get("response_url")
                if not result_url:
                    error = "–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
                    logger.error("Retoucher job {} task {} completed without result URL or result in status", job_id, task_id)
                    if job:
                        job.meta["error"] = error
                        job.save_meta()
                    if notify_options.get("chat_id"):
                        _send_failure_notification_sync(notify_options, job_id, error)
                    raise RuntimeError(error)

                # –ö–æ—Ä–æ—Ç–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, —á—Ç–æ–±—ã API —É—Å–ø–µ–ª –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–∫–∞–∫ –≤ Smart Merge)
                time.sleep(0.5)
                
                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–¥–Ω–∏–º –±—ã—Å—Ç—Ä—ã–º –≤—ã–∑–æ–≤–æ–º (–∫–∞–∫ –≤ Smart Merge), –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
                try:
                    asset = resolve_image_asset(result_url)
                    logger.info("Retoucher job {} successfully got result: asset.url={}, asset.content={}", 
                               job_id, asset.url[:100] if asset.url else "None", asset.content is not None)
                except Exception as exc:  # noqa: BLE001
                    error = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ—Ç—É—à–∏: {exc}"
                    logger.error("Retoucher job {} failed to get result: {}", job_id, exc)
                    if job:
                        job.meta["error"] = str(exc)
                        job.save_meta()
                    if notify_options.get("chat_id"):
                        _send_failure_notification_sync(notify_options, job_id, error)
                    raise RuntimeError(error)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ asset –±—ã–ª —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω
        if asset is None:
            error = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ—Ç—É—à–∏"
            logger.error("Retoucher job {}: asset is None after processing", job_id)
            if job:
                job.meta["error"] = error
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, error)
            raise RuntimeError(error)

        # –î–ª—è —Ä–µ–∂–∏–º–∞ "soft" –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ (–∫–∞–∫ —É Nano Banana create)
        # –î–ª—è —Ä–µ–∂–∏–º–∞ "enhance" –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ (–∫–∞–∫ –±—ã–ª–æ)
        is_soft_mode = mode == "soft"
        
        image_url = asset.url
        image_bytes = asset.content
        filename = asset.filename
        saved_path = None
        
        if is_soft_mode:
            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è –º—è–≥–∫–æ–π —Ä–µ—Ç—É—à–∏ - —Ç–æ—á–Ω–æ –∫–∞–∫ —É Nano Banana Smart Merge
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ URL —Å—Ä–∞–∑—É, –ë–ï–ó —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–∫–∞–∫ –≤ Smart Merge)
            if image_bytes is not None:
                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ –≤ –ø–∞–º—è—Ç–∏ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (–±—ã—Å—Ç—Ä–æ)
                saved_path = _persist_asset(asset, output_file.as_posix())
                logger.info("Retoucher job {} (soft mode): saving from memory ({} bytes) - no download needed", 
                           job_id, len(image_bytes))
            elif image_url:
                # –î–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ URL —Å—Ä–∞–∑—É (–∫–∞–∫ –≤ Smart Merge)
                # –ù–ï —Å–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª - Telegram —Å–∫–∞—á–∞–µ—Ç —Å–∞–º, —ç—Ç–æ –±—ã—Å—Ç—Ä–µ–µ
                logger.info("üîÑ Retoucher job {} (soft mode): Sending by URL immediately (no download, like Smart Merge)", job_id)
                saved_path = None
                # –ù–ï –ø–ª–∞–Ω–∏—Ä—É–µ–º —Ñ–æ–Ω–æ–≤–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ - —ç—Ç–æ –∑–∞–º–µ–¥–ª—è–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
                # –§–æ–Ω–æ–≤–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–Ω–∏–º–∞–µ—Ç –≤—Ä–µ–º—è –∏ –Ω–µ –Ω—É–∂–Ω–æ –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏
        else:
            # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è enhance - —Å–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
            if image_bytes is not None:
                saved_path = _persist_asset(asset, output_file.as_posix())
            elif image_url:
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ URL, —Å–∫–∞—á–∏–≤–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                saved_path = _persist_asset(asset, output_file.as_posix())
                if saved_path and saved_path.exists():
                    try:
                        image_bytes = saved_path.read_bytes()
                        filename = filename or saved_path.name
                    except Exception as read_exc:  # noqa: BLE001
                        logger.warning("Failed to read saved retouch result {} (enhance mode): {}", saved_path, read_exc)

        if job:
            if image_url:
                job.meta["image_url"] = image_url
            if image_bytes:
                job.meta["image_inline"] = True
                if filename:
                    job.meta["image_filename"] = filename
            if saved_path:
                job.meta["result_path"] = saved_path.as_posix()
            elif image_url:
                job.meta["result_path"] = None
            else:
                job.meta["result_path"] = None
            job.save_meta()

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—Ö–µ (—Ç–æ—á–Ω–æ –∫–∞–∫ —É Nano Banana create)
        if notify_options.get("chat_id"):
            try:
                reply_markup = None
                caption_title = "‚ú® –†–µ—Ç—É—à—å –≥–æ—Ç–æ–≤–∞!"
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º saved_path –∏–∑ job.meta –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ —Ñ–æ–Ω–æ–≤–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å
                if saved_path is None and job and job.meta.get("result_path"):
                    saved_path = Path(job.meta["result_path"])
                    if not saved_path.exists():
                        saved_path = None
                
                if image_bytes is not None:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_bytes=image_bytes,
                        filename=filename,
                        caption_title=caption_title,
                        reply_markup=reply_markup,
                    )
                elif saved_path and saved_path.exists():
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–º–µ—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    logger.info("Using already downloaded file for notification: {} (size: {:.2f} KB)", 
                               saved_path, saved_path.stat().st_size / 1024)
                    with open(saved_path, "rb") as f:
                        image_bytes = f.read()
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_bytes=image_bytes,
                        filename=filename or saved_path.name,
                        caption_title=caption_title,
                        reply_markup=reply_markup,
                    )
                elif image_url:
                    # –î–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ URL –Ω–∞–ø—Ä—è–º—É—é (–∫–∞–∫ –≤ Smart Merge)
                    # Telegram —Å–∫–∞—á–∞–µ—Ç —Ñ–∞–π–ª —Å–∞–º - —ç—Ç–æ –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º —Å–∫–∞—á–∏–≤–∞—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
                    logger.info("üì§ Sending by URL directly (no download, Telegram will download, like Smart Merge): {}", image_url[:100] if image_url else "None")
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_url=image_url,
                        caption_title=caption_title,
                        reply_markup=reply_markup,
                    )
                else:
                    logger.error("Retoucher job {}: no image_bytes, no saved_path, and no image_url to send", job_id)
            except Exception as notify_error:  # noqa: BLE001
                logger.error("Failed to send Telegram notification for retoucher job {}: {}", job_id, notify_error, exc_info=True)

        logger.info("Retoucher job {} completed successfully", job_id)
        
        # Confirm operation after successful completion
        if operation_id:
            from app.db.base import SessionLocal
            from app.services.billing import BillingService
            db = SessionLocal()
            try:
                success = BillingService.confirm_operation(db, operation_id)
                if success:
                    logger.info("Confirmed operation {} for retoucher job {}", operation_id, job_id)
                else:
                    logger.error("Failed to confirm operation {} for retoucher job {}", operation_id, job_id)
            except Exception as e:
                logger.error("Error confirming operation {} for retoucher job {}: {}", operation_id, job_id, e, exc_info=True)
            finally:
                db.close()
        
        return {
            "image_url": image_url,
            "image_bytes": image_bytes,
            "filename": filename,
            "saved_path": saved_path.as_posix() if saved_path else None,
        }

        return caption_path
    except JobTimeoutException as timeout_exc:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –∑–∞–¥–∞—á–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        logger.error("Retoucher job {} timed out after 4 minutes", job_id)
        _handle_job_timeout(job_id, notify_options, "—Ä–µ—Ç—É—à–∏")
        # Mark operation as failed
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for retoucher job {} due to timeout", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for retoucher job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise
    except Exception as e:
                    # Mark operation as failed on any error
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for retoucher job {} due to error", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for retoucher job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise


def process_smart_merge_job(
    job_id: str,
    prompt: str,
    image_sources: list[dict[str, str | None]],
    options: dict | None,
    output_path: str,
) -> str:
    # Import models to ensure they are registered with Base.metadata
    from app.db import models  # noqa: F401
    from app.services.billing import BillingService
    from app.db.base import SessionLocal

    if not image_sources:
        raise ValueError("Smart merge requires at least one image source")

    provider_options: Dict[str, Any] = dict(options or {})
    operation_id_raw = provider_options.pop("operation_id", None)
    operation_id = _parse_operation_id(operation_id_raw, job_id, "Smart merge")
    provider_prompt = provider_options.pop("provider_prompt", prompt)
    provider_options.setdefault("model", SMART_MERGE_DEFAULT_MODEL)
    
    # –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–û: Flux 2 Pro Edit - –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    # # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –î–ª—è Flux 2 Pro Edit –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –ü–ï–†–ï–î —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    # model_name = provider_options.get("model", "")
    # is_flux2pro = "flux-2-pro" in model_name.lower() and "/edit" in model_name.lower()
    # 
    # # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    # logger.info("Smart merge job {}: Initial provider_options keys: {}", job_id, list(provider_options.keys()))
    # logger.info("Smart merge job {}: width={}, height={}, size={}, aspect_ratio={}", 
    #            job_id, provider_options.get("width"), provider_options.get("height"), 
    #            provider_options.get("size"), provider_options.get("aspect_ratio"))
    # 
    # # –ï—Å–ª–∏ –µ—Å—Ç—å width –∏ height, –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º size –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    # # (width –∏ height –∏–º–µ—é—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤ _build_input_payload)
    # if "width" not in provider_options or "height" not in provider_options:
    #     # –î–ª—è Flux 2 Pro Edit –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã –Ω–µ –∑–∞–¥–∞–Ω—ã
    #     # –†–∞–∑–º–µ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–µ—Ä–µ–¥–∞–Ω—ã –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞
    #     if not is_flux2pro:
    #         provider_options.setdefault("size", SMART_MERGE_DEFAULT_SIZE)
    #         provider_options.setdefault("aspect_ratio", SMART_MERGE_DEFAULT_ASPECT_RATIO)
    #     else:
    #         logger.error("Smart merge job {}: Flux 2 Pro Edit detected but width/height not found in provider_options! Available keys: {}", 
    #                       job_id, list(provider_options.keys()))
    #         # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è Flux 2 Pro, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã
    #         provider_options.setdefault("width", 1024)
    #         provider_options.setdefault("height", 1024)
    #         logger.warning("Smart merge job {}: Using default 1024x1024 for Flux 2 Pro Edit", job_id)
    
    # –î–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –µ—Å–ª–∏ –Ω–µ—Ç width –∏ height
    if "width" not in provider_options or "height" not in provider_options:
        provider_options.setdefault("size", SMART_MERGE_DEFAULT_SIZE)
        provider_options.setdefault("aspect_ratio", SMART_MERGE_DEFAULT_ASPECT_RATIO)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å Nano-banana (–º–æ–≥—É—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç)
    # –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–û: Flux 2 Pro Edit - –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    model_name = provider_options.get("model", "")
    logger.info("Smart merge job {}: Processing with model='{}', image_sources count={}", job_id, model_name, len(image_sources) if image_sources else 0)
    is_nano_banana_regular = model_name == SMART_MERGE_DEFAULT_MODEL or model_name == "fal-ai/nano-banana" or ("nano-banana" in model_name.lower() and "pro" not in model_name.lower())
    is_nano_banana_pro = "nano-banana-pro" in model_name.lower()
    is_nano_banana = is_nano_banana_regular or is_nano_banana_pro
    # is_flux2pro = "flux-2-pro" in model_name.lower() and "/edit" in model_name.lower()
    # 
    # # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏ –¥–ª—è Flux 2 Pro
    # if is_flux2pro:
    #     logger.info("Smart merge job {}: Flux 2 Pro Edit detected! image_sources={}", job_id, image_sources)

    if is_nano_banana:  # or is_flux2pro:
        # –î–ª—è Nano-banana –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏–º –ø—Ä–æ–º–ø—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä—É—Å—Å–∫–∏–π
        # –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–û: Flux 2 Pro Edit
        model_type = "Nano Banana Pro" if is_nano_banana_pro else "Nano Banana"
        logger.info("Smart merge job {}: {} model detected, using original Russian prompt without translation", job_id, model_type)
        provider_prompt = prompt  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–∞
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è nano-banana (–æ–±—ã—á–Ω—ã–π –∏ pro) –∏ seedream –≤ Smart Merge
    is_seedream = "seedream" in model_name.lower()
    
    if is_nano_banana_regular:
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–æ–±—ã—á–Ω—ã–π nano-banana)
        provider_options["num_inference_steps"] = 90
        provider_options["guidance_scale"] = 11.0
        logger.info("Smart merge job {}: Applied quality settings for nano-banana: num_inference_steps={}, guidance_scale={}", 
                   job_id, provider_options.get("num_inference_steps"), provider_options.get("guidance_scale"))
    elif is_nano_banana_pro:
        # –ù–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –µ—Å–ª–∏ –æ–Ω–∏ —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ –±–æ—Ç–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –±—ã–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã
        if "num_inference_steps" not in provider_options:
            provider_options["num_inference_steps"] = 100  # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ 55
        if "guidance_scale" not in provider_options:
            provider_options["guidance_scale"] = 11.0  # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ 8.5
        logger.info("Smart merge job {}: Using parameters for nano-banana-pro: num_inference_steps={}, guidance_scale={}", 
                   job_id, provider_options.get("num_inference_steps"), provider_options.get("guidance_scale"))
    # –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–û: Flux 2 Pro Edit - –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    # elif is_flux2pro:
    #     # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è Flux 2 Pro Edit
    #     # Flux 2 Pro –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç multi-reference editing (–¥–æ 6 —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤), –ø–æ—ç—Ç–æ–º—É –≤–∞–∂–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å image_urls
    #     if "num_inference_steps" not in provider_options:
    #         provider_options["num_inference_steps"] = 100  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 100 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–º
    #     if "guidance_scale" not in provider_options:
    #         provider_options["guidance_scale"] = 7.5  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 7.5 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç—É –∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º
    #     # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    #     logger.info("Smart merge job {}: Applied enhanced quality settings for Flux 2 Pro Edit: num_inference_steps={}, guidance_scale={}, image_sources count={}, width={}, height={}, size={}", 
    #                job_id, provider_options.get("num_inference_steps"), provider_options.get("guidance_scale"), 
    #                len(image_sources) if image_sources else 0, provider_options.get("width"), provider_options.get("height"), provider_options.get("size"))
    elif is_seedream:
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è Seedream (—É–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –ø—Ä–æ—Ä–∏—Å–æ–≤–∫–∞ –∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è)
        provider_options["num_inference_steps"] = 120
        provider_options["guidance_scale"] = 12.0
        provider_options["enhance_prompt_mode"] = "standard"  # –î–æ–±–∞–≤–ª–µ–Ω –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–º–ø—Ç–∞
        logger.info("Smart merge job {}: Applied enhanced quality settings for Seedream: num_inference_steps={}, guidance_scale={}, enhance_prompt_mode={}", 
                   job_id, provider_options.get("num_inference_steps"), provider_options.get("guidance_scale"), provider_options.get("enhance_prompt_mode"))

    notify_options = _extract_notify_options(provider_options)
    output_file = Path(output_path)

    job = get_current_job()

    try:
        if job:
            job.meta.update(
                {
                    "prompt": prompt,
                    "smart_merge": True,
                    "sources": image_sources,
                }
            )
        if provider_prompt != prompt:
            job.meta["provider_prompt"] = provider_prompt
        job.save_meta()

        logger.info(
            "Processing smart merge job {} with {} images, prompt='{}', provider_prompt='{}'",
            job_id,
            len(image_sources),
            prompt,
            provider_prompt,
        )

        # –î–ª—è nano-banana/edit, nano-banana-pro/edit, flux-2-pro/edit –∏ seedream/edit –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º —á–µ—Ä–µ–∑ queue API
        # —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å worker'—ã –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–µ
        model_name = provider_options.get("model", "")
        is_nano_banana_edit = "nano-banana" in model_name.lower() and "/edit" in model_name.lower() and "pro" not in model_name.lower()
        is_nano_banana_pro_edit = "nano-banana-pro" in model_name.lower() and "/edit" in model_name.lower()
        is_flux2pro_edit = "flux-2-pro" in model_name.lower() and "/edit" in model_name.lower()
        is_seedream_edit = "seedream" in model_name.lower() and "/edit" in model_name.lower()
        
        if is_nano_banana_edit or is_nano_banana_pro_edit or is_flux2pro_edit or is_seedream_edit:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è nano-banana/edit, nano-banana-pro/edit –∏ seedream/edit
            from app.providers.fal.images import submit_smart_merge
            from app.providers.fal.images import check_status as check_image_status
            from app.providers.fal.images import resolve_result_asset as resolve_image_asset
            from app.providers.fal import images as fal_images
            
            if is_nano_banana_pro_edit:
                logger.info("Smart merge job {}: Using asynchronous queue mode for nano-banana-pro/edit", job_id)
            elif is_flux2pro_edit:
                logger.info("Smart merge job {}: Using asynchronous queue mode for flux-2-pro/edit", job_id)
            elif is_seedream_edit:
                logger.info("Smart merge job {}: Using asynchronous queue mode for seedream/edit", job_id)
            else:
                logger.info("Smart merge job {}: Using asynchronous queue mode for nano-banana/edit", job_id)
            try:
                task_id = submit_smart_merge(
                    image_sources=image_sources,
                    prompt=provider_prompt,
                    **provider_options,
                )
                
                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∫—ç—à–µ (–∏–∑ –æ—Ç–≤–µ—Ç–∞ queue_submit)
                cache_entry = fal_images._TASK_CACHE.get(task_id)
                queue_response = cache_entry.get("queue_response") if cache_entry else None
                
                # –ü—ã—Ç–∞–µ–º—Å—è —Å—Ä–∞–∑—É –∏–∑–≤–ª–µ—á—å URL –∏–∑ –æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ –∑–∞–¥–∞—á–∞ —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞
                result_url = None
                if queue_response:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –≥–æ—Ç–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –æ—Ç–≤–µ—Ç–µ
                    status_from_response = queue_response.get("status")
                    if status_from_response == "COMPLETED" or status_from_response == "succeeded":
                        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å URL –∏–∑ –æ—Ç–≤–µ—Ç–∞
                        from app.providers.fal.images import _extract_image_url
                        result_url = _extract_image_url(queue_response)
                        if result_url:
                            logger.info("Smart merge job {}: Got result URL immediately from queue_response", job_id)
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º resolve_result_asset –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ URL
                            asset = resolve_image_asset(result_url)
                            logger.info("Smart merge job {} successfully got result: asset.url={}, asset.content={}", 
                                       job_id, asset.url[:100] if asset.url else "None", asset.content is not None)
                            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º polling –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            image_url = asset.url
                            image_bytes = asset.content
                            filename = asset.filename
                            saved_path = None
                            if asset.content is not None:
                                saved_path = _persist_asset(asset, output_file.as_posix())
                            
                            if image_bytes is None and image_url:
                                logger.info("Smart merge: image not downloaded, will send by URL: {}", image_url[:100])
                            
                            if job:
                                if image_url:
                                    job.meta["image_url"] = image_url
                                if image_bytes:
                                    job.meta["image_inline"] = True
                                    if filename:
                                        job.meta["image_filename"] = filename
                                if saved_path:
                                    job.meta["result_path"] = saved_path.as_posix()
                                elif image_url:
                                    job.meta["result_path"] = None
                                job.save_meta()
                            
                            logger.success("Smart merge job {} completed: {}", job_id, image_url or filename or "binary")
                            if notify_options.get("chat_id"):
                                _send_success_notification_sync(notify_options, job_id, image_url, image_bytes, filename)
                            
                            if job:
                                operation_id = notify_options.get("operation_id")
                                if operation_id:
                                    from app.services.billing import BillingService
                                    from app.db.base import SessionLocal
                                    db = SessionLocal()
                                    try:
                                        BillingService.confirm_operation(db, operation_id)
                                        logger.info("Confirmed operation {} for smart merge job {}", operation_id, job_id)
                                    finally:
                                        db.close()
                            
                            return
                
                # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω —Å—Ä–∞–∑—É, –Ω–∞—á–∏–Ω–∞–µ–º polling
                logger.info("Smart merge job {}: Result not available immediately, starting polling for task {}", job_id, task_id)
                poll_attempts = 0
                max_attempts = 150  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 180 –¥–æ 150 (–ø—Ä–∏ 60 —à–∞–≥–∞—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±—ã—Å—Ç—Ä–µ–µ)
                poll_interval = 2.0  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 3.0 –¥–æ 2.0 —Å–µ–∫—É–Ω–¥ –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                max_interval = 6.0  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 8.0 –¥–æ 6.0 —Å–µ–∫—É–Ω–¥
                consecutive_progress = 0  # –°—á–µ—Ç—á–∏–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º "IN_PROGRESS"
                
                logger.info("Smart merge job {} polling for task {} completion", job_id, task_id)
                while True:
                    status = check_image_status(task_id)
                    current_status = status.get("status")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10 –ø–æ–ø—ã—Ç–æ–∫ –∏–ª–∏ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞
                    if poll_attempts % 10 == 0 or current_status not in ("processing", "queued", "IN_QUEUE", "IN_PROGRESS"):
                        logger.debug("Smart merge job {} task {} status: {} (attempt {}, interval: {:.1f}s)", 
                                   job_id, task_id, current_status, poll_attempts + 1, poll_interval)
                    
                    if current_status == "succeeded":
                        break
                    if current_status == "failed":
                        error = status.get("error", "Unknown error")
                        logger.error("Smart merge job {} task {} failed: {}", job_id, task_id, error)
                        if job:
                            job.meta["error"] = error
                            job.save_meta()
                        if notify_options.get("chat_id"):
                            _send_failure_notification_sync(notify_options, job_id, f"–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {error}")
                        raise RuntimeError(error)
                    
                    poll_attempts += 1
                    if poll_attempts >= max_attempts:
                        error = "–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–≤—ã—Å–∏–ª–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è"
                        logger.error("Smart merge job {} task {} timed out after {} attempts", job_id, task_id, poll_attempts)
                        if job:
                            job.meta["error"] = error
                            job.save_meta()
                        if notify_options.get("chat_id"):
                            _send_failure_notification_sync(notify_options, job_id, "–ó–∞–¥–∞—á–∞ –ø—Ä–µ–≤—ã—Å–∏–ª–∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                        raise RuntimeError(error)
                    
                    # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞: –µ—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –¥–æ–ª–≥–æ "IN_PROGRESS", —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –±—ã—Å—Ç—Ä–µ–µ
                    if current_status in ("IN_PROGRESS", "processing"):
                        consecutive_progress += 1
                        # –ü–æ—Å–ª–µ 5 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ "IN_PROGRESS" –Ω–∞—á–∏–Ω–∞–µ–º —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª –±—ã—Å—Ç—Ä–µ–µ
                        if consecutive_progress > 5:
                            poll_interval = min(poll_interval * 1.15, max_interval)
                        else:
                            poll_interval = min(poll_interval * 1.08, max_interval)
                    else:
                        consecutive_progress = 0
                        # –ï—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–∏–ª—Å—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "IN_QUEUE"), —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–¥–ª–µ–Ω–Ω–µ–µ
                        poll_interval = min(poll_interval * 1.05, max_interval)
                    
                    time.sleep(poll_interval)
                
                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                result_url = status.get("result_url") or status.get("response_url")
                if not result_url:
                    error = "–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
                    logger.error("Smart merge job {} task {} completed without result URL", job_id, task_id)
                    if job:
                        job.meta["error"] = error
                        job.save_meta()
                    if notify_options.get("chat_id"):
                        _send_failure_notification_sync(notify_options, job_id, error)
                    raise RuntimeError(error)
                
                time.sleep(0.5)
                asset = resolve_image_asset(result_url)
                logger.info("Smart merge job {} successfully got result: asset.url={}, asset.content={}", 
                           job_id, asset.url[:100] if asset.url else "None", asset.content is not None)
            except Exception as exc:  # noqa: BLE001
                logger.error("Smart merge job {} asynchronous mode failed: {}", job_id, exc)
                if job:
                    job.meta["error"] = str(exc)
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, f"–û—à–∏–±–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {exc}")
                raise
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º (–∫–∞–∫ –±—ã–ª–æ)
            try:
                asset = run_smart_merge(
                    image_sources=image_sources,
                    prompt=provider_prompt,
                    **provider_options,
                )
            except Exception as exc:  # noqa: BLE001
                logger.error("Smart merge job {} failed: {}", job_id, exc)
                if job:
                    job.meta["error"] = str(exc)
                    job.save_meta()
                if notify_options.get("chat_id"):
                    failure_text = "–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
                    if isinstance(exc, ValueError):
                        failure_text = "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
                    _send_failure_notification_sync(
                        notify_options,
                        job_id,
                        failure_text,
                    )
                raise

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –ª–æ–≥–∏–∫—É, —á—Ç–æ –∏ –≤ process_image_job
        image_url = asset.url
        image_bytes = asset.content
        filename = asset.filename
        saved_path = None
        if asset.content is not None:
            saved_path = _persist_asset(asset, output_file.as_posix())

        # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –±—ã–ª–æ —Å–∫–∞—á–∞–Ω–æ, –Ω–æ –µ—Å—Ç—å URL, –ø—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å —Å –∫–æ—Ä–æ—Ç–∫–∏–º —Ç–∞–π–º–∞—É—Ç–æ–º
        # –ï—Å–ª–∏ –Ω–µ —É—Å–ø–µ–≤–∞–µ—Ç –±—ã—Å—Ç—Ä–æ —Å–∫–∞—á–∞—Ç—å—Å—è, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ URL (Telegram –º–æ–∂–µ—Ç –ø—Ä–∏–Ω—è—Ç—å URL –Ω–∞–ø—Ä—è–º—É—é)
        if image_bytes is None and image_url:
            # –ù–µ –ø—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∏–≤–∞—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ - —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ URL, Telegram –æ–±—ã—á–Ω–æ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç URL –æ—Ç fal.media
            logger.info("Smart merge: image not downloaded, will send by URL: {}", image_url[:100])

        if job:
            if image_url:
                job.meta["image_url"] = image_url
            if image_bytes:
                job.meta["image_inline"] = True
                if filename:
                    job.meta["image_filename"] = filename
            if saved_path:
                job.meta["result_path"] = saved_path.as_posix()
            elif image_url:
                job.meta["result_path"] = None
            job.save_meta()

        # –ù–µ –∑–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–ª—è Smart Merge - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ URL —Å—Ä–∞–∑—É
        # –§–æ–Ω–æ–≤–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–∂–µ—Ç –∑–∞–Ω–∏–º–∞—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –Ω–µ –Ω—É–∂–Ω–æ –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏
        # if saved_path is None and image_url:
        #     _schedule_result_download(job_id, image_url, output_file)

        logger.success("Smart merge job {} completed: {}", job_id, image_url or filename or "binary")
        if notify_options.get("chat_id"):
            try:
                reply_markup = None
                if image_bytes is not None:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_bytes=image_bytes,
                        filename=filename,
                        caption_title="–ì–æ—Ç–æ–≤–æ",
                        reply_markup=reply_markup,
                    )
                else:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_url=image_url,
                        caption_title="–ì–æ—Ç–æ–≤–æ",
                        reply_markup=reply_markup,
                    )
            except Exception as notify_error:  # noqa: BLE001
                logger.error("Failed to send Telegram notification for smart merge job {}: {}", job_id, notify_error)

        # Confirm operation after successful completion
        if operation_id:
            db = SessionLocal()
            try:
                success = BillingService.confirm_operation(db, operation_id)
                if success:
                    logger.info("Confirmed operation {} for smart merge job {}", operation_id, job_id)
                else:
                    logger.error("Failed to confirm operation {} for smart merge job {}", operation_id, job_id)
            except Exception as e:
                logger.error("Error confirming operation {} for smart merge job {}: {}", operation_id, job_id, e, exc_info=True)
            finally:
                db.close()

        return image_url or ""
    except JobTimeoutException as timeout_exc:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –∑–∞–¥–∞—á–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        logger.error("Smart merge job {} timed out after 4 minutes", job_id)
        _handle_job_timeout(job_id, notify_options, "–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        # Mark operation as failed
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for smart merge job {} due to timeout", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for smart merge job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise
    except Exception as e:
        # Mark operation as failed on any error
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for smart merge job {} due to error", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for smart merge job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise


def process_image_upscale_job(
    job_id: str,
    image_url: str | None,
    image_path: str | None,
    scale: int,
    options: dict | None,
    output_path: str,
) -> str:
    # Import models to ensure they are registered with Base.metadata
    from app.db import models  # noqa: F401
    from app.services.billing import BillingService
    from app.db.base import SessionLocal

    provider_options: Dict[str, Any] = dict(options or {})
    operation_id_raw = provider_options.pop("operation_id", None)
    operation_id = _parse_operation_id(operation_id_raw, job_id, "Upscale")
    scale_value = int(provider_options.pop("scale", scale or 2))
    if scale_value > 2:
        logger.debug("Clamping upscale scale {} to 2 to limit output size", scale_value)
        scale_value = 2
    model_name = provider_options.setdefault("model", settings.fal_upscale_model)
    provider_options.pop("model", None)
    provider_options.pop("fallback_model", None)  # Remove fallback if present

    notify_options = _extract_notify_options(provider_options)
    output_file = Path(output_path)

    job = get_current_job()
    
    try:
        if job:
            job.meta.update(
                {
                    "upscale": True,
                    "source_url": image_url,
                    "scale": scale_value,
                    "model": model_name,
                }
            )
            job.save_meta()
    except Exception:
        pass  # Ignore errors in job meta update

    try:
        cleanup_paths: list[Path] = []
        local_input_path: Path | None = None
        input_dimensions = None
        if image_path:
            candidate = Path(image_path)
            if candidate.exists():
                local_input_path = candidate
            else:
                logger.warning("Provided image_path {} does not exist for upscale job {}", image_path, job_id)

        if local_input_path is None and image_url:
            fd, tmp_name = tempfile.mkstemp(suffix=".png")
            os.close(fd)
            tmp_path = Path(tmp_name)
            try:
                _download_file_with_retry(image_url, tmp_path.as_posix())
                cleanup_paths.append(tmp_path)
                local_input_path = tmp_path
            except Exception as download_exc:  # noqa: BLE001
                logger.error("Failed to download source image for upscale job {}: {}", job_id, download_exc)
                if tmp_path.exists():
                    tmp_path.unlink(missing_ok=True)
                raise

        if local_input_path:
            try:
                with Image.open(local_input_path) as input_image:
                    prepared = input_image.convert("RGB")
                    max_edge = max(prepared.size)
                    original_input_size = f"{prepared.width}x{prepared.height}"
                    # Don't reduce input size - let the model handle it
                    # The model should accept images up to reasonable size
                    # Only log if we would have reduced it
                    if max_edge > UPSCALE_INPUT_MAX_EDGE:
                        logger.info(
                            "Upscale job {}: input image {}x{} exceeds {}px limit, but sending as-is (model should handle it)",
                            job_id,
                            prepared.width,
                            prepared.height,
                            UPSCALE_INPUT_MAX_EDGE,
                        )
                    else:
                        # Calculate input file size
                        input_file_size = local_input_path.stat().st_size / (1024 * 1024)
                        logger.info(
                            "Upscale job {}: input image size {}x{} (file size: {:.2f}MB, format: PNG)",
                            job_id,
                            prepared.width,
                            prepared.height,
                            input_file_size,
                        )
                    fd, png_name = tempfile.mkstemp(suffix=".png")
                    os.close(fd)
                    png_path = Path(png_name)
                    prepared.save(png_path.as_posix(), "PNG", optimize=True)
                    cleanup_paths.append(png_path)
                    local_input_path = png_path
                    input_dimensions = original_input_size
            except Exception as prepare_exc:  # noqa: BLE001
                logger.warning("Failed to preprocess upscale input for job {}: {}", job_id, prepare_exc)

        # Log input image dimensions
        if input_dimensions is None and local_input_path and local_input_path.exists():
            try:
                with Image.open(local_input_path) as img:
                    input_dimensions = f"{img.width}x{img.height}"
            except Exception:
                pass

        logger.info(
            "Processing image upscale job {} for url={}, path={} (scale={}, input_size={})",
            job_id,
            image_url,
            image_path,
            scale_value,
            input_dimensions or "unknown",
        )

        if local_input_path is None:
            error = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–ø—Å–∫–µ–π–ª–∞."
            logger.error("Upscale job {} missing source image (url={}, path={})", job_id, image_url, image_path)
            if job:
                job.meta["error"] = error
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, error)
            raise RuntimeError(error)

        # Use queue API for more reliable processing (async approach like face swap)
        attempts = 0
        delay = UPSCALE_RETRY_BASE_DELAY
        last_error: Exception | None = None
        task_id: str | None = None
        used_model = model_name

        # Add parameters to control output format - request JPEG format with quality for file size control
        upscale_options = dict(provider_options)
        # Request PNG format for all upscale models
        # Note: Some models may not support output_format parameter, but we try anyway
        if model_name in ("fal-ai/recraft/upscale/crisp", "fal-ai/recraft/upscale/creative", "fal-ai/esrgan"):
            # Request PNG format
            upscale_options.setdefault("output_format", "png")
            logger.info("Upscale job {}: requesting PNG output format for model {}", 
                       job_id, model_name)

        # Try primary model first
        while attempts < UPSCALE_MAX_ATTEMPTS:
            try:
                logger.info("Upscale job {}: calling submit_image_upscale with upscale_options: {}", 
                           job_id, {k: v for k, v in upscale_options.items() if not k.startswith("notify_") and not k.startswith("source_")})
                task_id = submit_image_upscale(
                    image_url=None,
                    image_path=local_input_path.as_posix() if local_input_path else None,
                    scale=scale_value,
                    model=model_name,
                    **upscale_options,
                )
                logger.info("Upscale job {} submitted to queue with task_id: {} (model: {})", job_id, task_id, model_name)
                break
            except Exception as exc:  # noqa: BLE001
                last_error = exc
                attempts += 1
                logger.info("Upscale job {} submit attempt {} caught exception: {} ({})", 
                           job_id, attempts, type(exc).__name__, exc)
                is_retryable = _is_retryable_error(exc)
                logger.info("Upscale job {} submit attempt {}: is_retryable={}, attempts_left={}", 
                           job_id, attempts, is_retryable, UPSCALE_MAX_ATTEMPTS - attempts)
                if is_retryable and attempts < UPSCALE_MAX_ATTEMPTS:
                    error_type = "network/server" if isinstance(exc, (httpx.RequestError, httpx.HTTPStatusError)) else "error"
                    logger.warning(
                        "Upscale job {} submit attempt {} failed due to {} issue: {}. Retrying in {:.1f}s",
                        job_id,
                        attempts,
                        error_type,
                        exc,
                        delay,
                    )
                    time.sleep(delay)
                    delay *= 2
                    continue
                logger.error("Upscale job {} submit failed after {} attempts: {}", job_id, attempts, exc)

                # Determine error message based on error type
                if isinstance(exc, httpx.HTTPStatusError):
                    status_code = exc.response.status_code
                    if status_code == 500:
                        error_msg = (
                            "–°–µ—Ä–≤–µ—Ä –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–æ—à–∏–±–∫–∞ 500). "
                            "–≠—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ —Å–µ—Ä–≤–∏—Å–∞ fal.ai. "
                            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."
                        )
                    elif status_code == 422:
                        error_msg = (
                            "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ (–æ—à–∏–±–∫–∞ 422). "
                            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
                        )
                    elif status_code == 429:
                        error_msg = (
                            "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ—à–∏–±–∫–∞ 429). "
                            "–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
                        )
                    else:
                        error_msg = f"–û—à–∏–±–∫–∞ API (–∫–æ–¥ {status_code}). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
                elif isinstance(exc, httpx.RequestError):
                    error_msg = (
                        "–ü—Ä–æ–±–ª–µ–º–∞ —Å —Å–µ—Ç—å—é –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API. "
                        "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
                    )
                else:
                    error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞ —É–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(exc)}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

                if job:
                    job.meta["error"] = str(exc)
                    job.meta["error_message"] = error_msg
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(
                        notify_options,
                        job_id,
                        error_msg,
                    )
                raise

        if task_id is None:
            error = last_error or RuntimeError("Upscale task submission failed")
            if job:
                job.meta["error"] = str(error)
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, str(error))
            raise RuntimeError(str(error))

        # Cleanup temporary input files before polling (they're no longer needed)
        for tmp in cleanup_paths:
            try:
                tmp.unlink(missing_ok=True)
            except OSError:
                logger.debug("Failed to remove temporary file {} after upscale job {}", tmp, job_id)

        # Poll for completion using queue API
        logger.info("Upscale job {} polling for task {} completion", job_id, task_id)
        status = check_image_status(task_id)
        poll_attempts = 0

        while status["status"] not in ("succeeded", "failed"):
            if poll_attempts >= UPSCALE_POLL_MAX_ATTEMPTS:
                error = "Upscale task timed out after polling"
                logger.error("Upscale job {} task {} timed out", job_id, task_id)
                if job:
                    job.meta["error"] = error
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, "–ó–∞–¥–∞—á–∞ –ø—Ä–µ–≤—ã—Å–∏–ª–∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                raise RuntimeError(error)

            poll_attempts += 1
            time.sleep(5)  # Poll every 5 seconds
            status = check_image_status(task_id)
            logger.debug("Upscale job {} task {} status: {}", job_id, task_id, status["status"])

            if status["status"] == "failed":
                error = status.get("error", "Unknown error")
                logger.error("Upscale job {} task {} failed: {}", job_id, task_id, error)
                if job:
                    job.meta["error"] = error
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, f"–£–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ —É–¥–∞–ª–æ—Å—å: {error}")
                # Mark operation as failed on error
                if operation_id:
                    db = SessionLocal()
                    try:
                        BillingService.fail_operation(db, operation_id)
                        logger.info("Marked operation {} as failed for upscale job {} due to error", operation_id, job_id)
                    except Exception as fail_error:
                        logger.error("Error failing operation {} for upscale job {}: {}", operation_id, job_id, fail_error, exc_info=True)
                    finally:
                        db.close()
                raise RuntimeError(error)

        # After the while loop, status is either "succeeded" or "failed"
        # According to fal.ai docs, when status is COMPLETED, the result may be in the status response itself
        # or available via response_url. Let's check if result is already in status first.
        from app.providers.fal.images import _extract_image_url as extract_image_url
        status_image_url = extract_image_url(status)
        logger.debug("Upscale job {} extracted URL from status: {}", job_id, status_image_url[:100] if status_image_url else "None")
        asset = None

        if status_image_url:
            # Check if this is a queue API endpoint (response_url) or a real image URL
            if status_image_url.startswith("https://queue.fal.run") or status_image_url.startswith("http://queue.fal.run"):
                # This is a queue API endpoint, not a direct image URL - skip it
                logger.info("Upscale job {} found response_url in status (not a direct image URL), will use resolve_image_asset", job_id)
                status_image_url = None
                asset = None  # Ensure asset is None so we use resolve_image_asset
            elif status_image_url.startswith("data:"):
                logger.info("Upscale job {} result found in status response (data URL)", job_id)
                # Result is already in status as data URL, extract it directly
                from app.providers.fal.images import ImageAsset
                import base64
                header, _, data_part = status_image_url.partition(",")
                content = base64.b64decode(data_part)
                asset = ImageAsset(url=None, content=content, filename="upscale.png")
            elif status_image_url.startswith("http"):
                # This looks like a direct image URL (CDN, etc.)
                logger.info("Upscale job {} result found in status response (direct URL): {}", job_id, status_image_url[:100])
                from app.providers.fal.images import ImageAsset
                asset = ImageAsset(url=status_image_url, content=None, filename=None)
            else:
                logger.warning("Upscale job {} unexpected image URL format in status: {}", job_id, status_image_url[:100])

        # If result not in status, try to get it via response_url with retries
        if asset is None:
            result_url = status.get("result_url")
            if not result_url:
                error = "Upscale task completed but no result URL provided and no result in status"
                logger.error("Upscale job {} task {} completed without result URL or result in status", job_id, task_id)
                if job:
                    job.meta["error"] = error
                    job.save_meta()
                if notify_options.get("chat_id"):
                    _send_failure_notification_sync(notify_options, job_id, "–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
                raise RuntimeError(error)

            # Small delay after completion to allow API to prepare the result
            # Sometimes the API returns 500 immediately after COMPLETED status
            logger.debug("Upscale job {} task {} completed, waiting 1s before fetching result", job_id, task_id)
            time.sleep(1.0)

            # Try to get result with retries and increasing delays
            # Use resolve_image_asset which properly handles authorization and retries
            max_result_attempts = 5
            result_delay = 1.0
            last_result_error: Exception | None = None
            api_file_size: int | None = None  # Store file_size from API response

            for result_attempt in range(max_result_attempts):
                try:
                    logger.debug("Upscale job {} attempt {} to get result from {}", job_id, result_attempt + 1, result_url)

                    # Try to extract file_size from API response before calling resolve_image_asset
                    from app.providers.fal.images import _parse_result_url
                    from app.providers.fal.client import queue_result
                    parsed = _parse_result_url(result_url)
                    if parsed:
                        model_path, request_id = parsed
                        try:
                            response_data = queue_result(model_path, request_id)
                            if isinstance(response_data, dict):
                                # Check common structures: {'image': {'file_size': ...}} or {'file_size': ...}
                                if 'image' in response_data and isinstance(response_data['image'], dict):
                                    extracted_size = response_data['image'].get('file_size')
                                    if extracted_size:
                                        api_file_size = extracted_size
                                        logger.info("Upscale job {}: extracted file_size {} bytes ({:.2f}MB) from API response", 
                                                   job_id, api_file_size, api_file_size / (1024 * 1024))
                                elif 'file_size' in response_data:
                                    extracted_size = response_data.get('file_size')
                                    if extracted_size:
                                        api_file_size = extracted_size
                                        logger.info("Upscale job {}: extracted file_size {} bytes ({:.2f}MB) from API response", 
                                                   job_id, api_file_size, api_file_size / (1024 * 1024))
                        except Exception as size_extract_exc:  # noqa: BLE001
                            logger.debug("Upscale job {}: could not extract file_size from API response: {}", job_id, size_extract_exc)

                    # Use resolve_image_asset which properly handles queue API authorization
                    asset = resolve_image_asset(result_url)
                    logger.info("Upscale job {} successfully got result on attempt {}: asset.url={}, asset.content={}", 
                               job_id, result_attempt + 1, asset.url[:100] if asset.url else "None", asset.content is not None)
                    # Check if asset.url is a queue API endpoint - if so, we need to get the actual image URL
                    if asset.url and (asset.url.startswith("https://queue.fal.run") or asset.url.startswith("http://queue.fal.run")):
                        logger.warning("Upscale job {} asset.url is a queue API endpoint, this should not happen. asset.url={}", 
                                      job_id, asset.url)
                        # Try to get the actual result from queue_result
                        from app.providers.fal.client import queue_result
                        from app.providers.fal.images import _extract_image_url, ImageAsset, _parse_result_url
                        parsed = _parse_result_url(result_url)
                        if parsed:
                            model_path, request_id = parsed
                            logger.info("Upscale job {} trying queue_result directly for model={}, request_id={}", 
                                       job_id, model_path, request_id)
                            response_data = queue_result(model_path, request_id)
                            logger.info("Upscale job {} queue_result response keys: {}", job_id, list(response_data.keys()) if isinstance(response_data, dict) else "not a dict")
                            actual_image_url = _extract_image_url(response_data)
                            # Try to extract file_size from response_data
                            if isinstance(response_data, dict):
                                # Check common structures: {'image': {'file_size': ...}} or {'file_size': ...}
                                if 'image' in response_data and isinstance(response_data['image'], dict):
                                    api_file_size = response_data['image'].get('file_size')
                                elif 'file_size' in response_data:
                                    api_file_size = response_data['file_size']
                                if api_file_size:
                                    logger.info("Upscale job {}: extracted file_size {} bytes ({:.2f}MB) from API response", 
                                               job_id, api_file_size, api_file_size / (1024 * 1024))
                            if actual_image_url and not (actual_image_url.startswith("https://queue.fal.run") or actual_image_url.startswith("http://queue.fal.run")):
                                logger.info("Upscale job {} extracted actual image URL: {}", job_id, actual_image_url[:100])
                                asset = ImageAsset(url=actual_image_url, content=None, filename=None)
                            else:
                                logger.error("Upscale job {} failed to extract valid image URL from queue_result response", job_id)
                    break
                except Exception as exc:  # noqa: BLE001
                    last_result_error = exc
                    # Check if it's an HTTP error that we can retry
                    if isinstance(exc, httpx.HTTPStatusError):
                        status_code = exc.response.status_code
                        if status_code in (500, 502, 503, 401) and result_attempt < max_result_attempts - 1:
                            logger.warning(
                                "Upscale job {} result attempt {} failed with {}: {}. Retrying in {:.1f}s",
                                job_id,
                                result_attempt + 1,
                                status_code,
                                exc.response.text[:100] if hasattr(exc.response, 'text') else str(exc),
                                result_delay,
                            )
                            time.sleep(result_delay)
                            result_delay *= 1.5
                            continue
                        else:
                            logger.error("Upscale job {} result attempt {} failed with {}: {}", job_id, result_attempt + 1, status_code, exc)
                            raise
                    else:
                        logger.error("Upscale job {} result attempt {} failed: {}", job_id, result_attempt + 1, exc)
                        if result_attempt >= max_result_attempts - 1:
                            raise

        if asset is None:
            error_msg = str(last_result_error) if last_result_error else "Failed to get upscale result"
            logger.error("Upscale job {} failed to get result after {} attempts: {}", job_id, max_result_attempts, error_msg)
            if job:
                job.meta["error"] = error_msg
                job.save_meta()
            if notify_options.get("chat_id"):
                _send_failure_notification_sync(notify_options, job_id, f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {error_msg}")
            # Mark operation as failed
            if operation_id:
                db = SessionLocal()
                try:
                    BillingService.fail_operation(db, operation_id)
                    logger.info("Marked operation {} as failed for upscale job {} due to error", operation_id, job_id)
                except Exception as fail_error:
                    logger.error("Error failing operation {} for upscale job {}: {}", operation_id, job_id, fail_error, exc_info=True)
                finally:
                    db.close()
            raise RuntimeError(error_msg)

        if asset is None:
            raise RuntimeError("fal upscale did not return an asset")

        # Use same approach as Smart merge - send by URL directly
        # This avoids download timeouts and Telegram handles the download server-side
        # send_document with URL doesn't compress files, so quality is preserved
        saved_path = _persist_asset(asset, output_file.as_posix(), skip_download=True)
        logger.info("Upscale: _persist_asset returned saved_path={}, asset.url={}, asset.content={}", 
                saved_path, asset.url, asset.content is not None)

        # Schedule background download for caching, but don't block sending
        if asset.url:
            _schedule_result_download(job_id, asset.url, output_file)
            logger.debug("Scheduled background download for upscale result: {} -> {}", asset.url, output_file)

        caption_url = asset.url
        image_bytes = asset.content
        filename = asset.filename

        # If no image_bytes but saved_path exists, read file (for fallback)
        if image_bytes is None and saved_path and saved_path.exists():
            try:
                image_bytes = saved_path.read_bytes()
                filename = filename or saved_path.name
                logger.debug("Read upscale result from file: {} ({} bytes)", saved_path, len(image_bytes))
            except Exception as read_exc:  # noqa: BLE001
                logger.warning("Failed to read saved upscale result {}: {}", saved_path, read_exc)

        if job:
            if asset.url:
                job.meta["image_url"] = asset.url
            if asset.content:
                job.meta["image_inline"] = True
                if asset.filename:
                    job.meta["image_filename"] = asset.filename
                if saved_path:
                    job.meta["result_path"] = saved_path.as_posix()
                else:
                    job.meta["result_path"] = None
            job.save_meta()

        if notify_options.get("chat_id"):
            try:
                logger.info(
                    "Sending upscale notification: job_id={}, has_bytes={}, has_url={}, filename={}",
                    job_id,
                    image_bytes is not None,
                    bool(caption_url),
                    filename,
                )
                if image_bytes is not None:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_bytes=image_bytes,
                        filename=filename,
                        caption_title="üîç –£–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤–æ!",
                        reply_markup=None,
                    )
                    logger.info("Upscale notification sent successfully with image bytes")
                elif caption_url:
                    _send_success_notification_sync(
                        notify_options,
                        job_id,
                        image_url=caption_url,
                        caption_title="üîç –£–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤–æ!",
                        reply_markup=None,
                    )
                    logger.info("Upscale notification sent successfully with image URL")
                else:
                    logger.error("Upscale job {}: no image_bytes and no image_url to send", job_id)
            except Exception as notify_error:  # noqa: BLE001
                logger.error("Failed to send Telegram notification for upscale job {}: {}", job_id, notify_error, exc_info=True)

        # Confirm operation after successful completion
        if operation_id:
            db = SessionLocal()
            try:
                success = BillingService.confirm_operation(db, operation_id)
                if success:
                    logger.info("Confirmed operation {} for upscale job {}", operation_id, job_id)
                else:
                    logger.error("Failed to confirm operation {} for upscale job {}", operation_id, job_id)
            except Exception as e:
                logger.error("Error confirming operation {} for upscale job {}: {}", operation_id, job_id, e, exc_info=True)
            finally:
                db.close()

        return caption_url or ""
    except JobTimeoutException as timeout_exc:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –∑–∞–¥–∞—á–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        logger.error("Upscale job {} timed out after 4 minutes", job_id)
        _handle_job_timeout(job_id, notify_options, "—É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞")
        # Mark operation as failed
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for upscale job {} due to timeout", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for upscale job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise
    except Exception as e:
        # Mark operation as failed on any error
        if operation_id:
            db = SessionLocal()
            try:
                BillingService.fail_operation(db, operation_id)
                logger.info("Marked operation {} as failed for upscale job {} due to error", operation_id, job_id)
            except Exception as fail_error:
                logger.error("Error failing operation {} for upscale job {}: {}", operation_id, job_id, fail_error, exc_info=True)
            finally:
                db.close()
        raise